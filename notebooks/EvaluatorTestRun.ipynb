{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator Test Run\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AseiSugiyama/TFXTestRun/blob/master/notebooks/EvaluatorTestRun.ipynb)\n",
    "\n",
    "## Set up\n",
    "\n",
    "TFX requires apache-airflow and docker SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: apache-airflow[gcp_api] in /usr/local/lib/python3.5/dist-packages (1.10.4)\n",
      "Requirement already satisfied: docker in /usr/local/lib/python3.5/dist-packages (4.0.2)\n",
      "Requirement already satisfied: tfx in /usr/local/lib/python3.5/dist-packages (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.3 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (2.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (2.22.0)\n",
      "Requirement already satisfied: tzlocal<2.0.0,>=1.4 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.5.1)\n",
      "Requirement already satisfied: zope.deprecation<5.0,>=4.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (4.4.0)\n",
      "Requirement already satisfied: lazy-object-proxy~=1.3 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.4.1)\n",
      "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.2)\n",
      "Requirement already satisfied: flask-admin==1.5.3 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.5.3)\n",
      "Requirement already satisfied: python-daemon<2.2,>=2.1.1 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (2.1.2)\n",
      "Requirement already satisfied: markdown<3.0,>=2.5.2 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (2.6.11)\n",
      "Requirement already satisfied: tenacity==4.12.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (4.12.0)\n",
      "Requirement already satisfied: cached-property~=1.5 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.5.1)\n",
      "Requirement already satisfied: setproctitle<2,>=1.1.8 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.1.10)\n",
      "Requirement already satisfied: unicodecsv>=0.14.1 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.14.1)\n",
      "Requirement already satisfied: croniter<0.4,>=0.3.17 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.3.30)\n",
      "Requirement already satisfied: future<0.17,>=0.16.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.16.0)\n",
      "Requirement already satisfied: gunicorn<20.0,>=19.5.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (19.9.0)\n",
      "Requirement already satisfied: dumb-init>=1.2.2 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.2.2)\n",
      "Requirement already satisfied: jinja2<2.11.0,>=2.10.1 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (2.10.1)\n",
      "Requirement already satisfied: flask-appbuilder<2.0.0,>=1.12.5 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.13.1)\n",
      "Requirement already satisfied: dill<0.3,>=0.2.2 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.2.9)\n",
      "Requirement already satisfied: configparser<3.6.0,>=3.5.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (3.5.3)\n",
      "Requirement already satisfied: funcsigs==1.0.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.0.0)\n",
      "Requirement already satisfied: flask-wtf<0.15,>=0.14.2 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.14.2)\n",
      "Requirement already satisfied: flask-login<0.5,>=0.3 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.4.1)\n",
      "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.1.0)\n",
      "Requirement already satisfied: psutil<6.0.0,>=4.2.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (5.6.3)\n",
      "Requirement already satisfied: tabulate<0.9,>=0.7.5 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.8.3)\n",
      "Requirement already satisfied: pandas<1.0.0,>=0.17.1 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.24.2)\n",
      "Requirement already satisfied: flask-swagger==0.2.13 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.2.13)\n",
      "Requirement already satisfied: pendulum==1.4.4 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.4.4)\n",
      "Requirement already satisfied: alembic<2.0,>=1.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.0.11)\n",
      "Requirement already satisfied: pygments<3.0,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (2.3.1)\n",
      "Requirement already satisfied: sqlalchemy~=1.3 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.3.6)\n",
      "Requirement already satisfied: thrift>=0.9.2 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.11.0)\n",
      "Requirement already satisfied: iso8601>=0.1.12 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.1.12)\n",
      "Requirement already satisfied: json-merge-patch==0.2 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.2)\n",
      "Requirement already satisfied: colorlog==4.0.2 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (4.0.2)\n",
      "Requirement already satisfied: flask<2.0,>=1.1.0 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.1.1)\n",
      "Requirement already satisfied: flask-caching<1.4.0,>=1.3.3 in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.3.3)\n",
      "Requirement already satisfied: google-api-python-client<2.0.0dev,>=1.6.0; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.7.10)\n",
      "Requirement already satisfied: google-cloud-videointelligence>=1.7.0; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.10.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.1; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.0.3)\n",
      "Requirement already satisfied: pandas-gbq; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.11.0)\n",
      "Requirement already satisfied: google-cloud-vision>=0.35.2; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.38.1)\n",
      "Requirement already satisfied: PyOpenSSL; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (19.0.0)\n",
      "Requirement already satisfied: httplib2~=0.9.2; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.9.2)\n",
      "Requirement already satisfied: google-cloud-texttospeech>=0.4.0; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.5.0)\n",
      "Requirement already satisfied: google-cloud-storage~=1.16; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.18.0)\n",
      "Requirement already satisfied: google-auth<2.0.0dev,>=1.0.0; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.6.3)\n",
      "Requirement already satisfied: google-cloud-language>=1.1.1; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.3.0)\n",
      "Requirement already satisfied: google-cloud-dlp>=0.11.0; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.12.1)\n",
      "Requirement already satisfied: google-cloud-container>=0.1.1; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.3.0)\n",
      "Requirement already satisfied: google-cloud-spanner<1.10.0,>=1.7.1; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.9.0)\n",
      "Requirement already satisfied: google-cloud-bigtable==0.33.0; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.33.0)\n",
      "Requirement already satisfied: grpcio-gcp>=0.2.2; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (0.2.2)\n",
      "Requirement already satisfied: google-cloud-translate>=1.3.3; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.6.0)\n",
      "Requirement already satisfied: google-cloud-speech>=0.36.3; extra == \"gcp_api\" in /usr/local/lib/python3.5/dist-packages (from apache-airflow[gcp_api]) (1.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.5/dist-packages (from docker) (1.12.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.5/dist-packages (from docker) (0.56.0)\n",
      "Requirement already satisfied: tensorflow-model-analysis<0.14,>=0.13.2 in /usr/local/lib/python3.5/dist-packages (from tfx) (0.13.2)\n",
      "Requirement already satisfied: ml-metadata<0.14,>=0.13.2 in /usr/local/lib/python3.5/dist-packages (from tfx) (0.13.2)\n",
      "Requirement already satisfied: tensorflow-transform<0.14,>=0.13 in /usr/local/lib/python3.5/dist-packages (from tfx) (0.13.0)\n",
      "Requirement already satisfied: tensorflow-data-validation<0.14,>=0.13.1 in /usr/local/lib/python3.5/dist-packages (from tfx) (0.13.1)\n",
      "Requirement already satisfied: absl-py<1,>=0.1.6 in /usr/local/lib/python3.5/dist-packages (from tfx) (0.7.1)\n",
      "Requirement already satisfied: apache-beam[gcp]<3,>=2.12 in /usr/local/lib/python3.5/dist-packages (from tfx) (2.14.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.7 in /usr/local/lib/python3.5/dist-packages (from tfx) (3.7.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.20.0->apache-airflow[gcp_api]) (1.25.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.20.0->apache-airflow[gcp_api]) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.20.0->apache-airflow[gcp_api]) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests<3,>=2.20.0->apache-airflow[gcp_api]) (2019.6.16)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.5/dist-packages (from tzlocal<2.0.0,>=1.4->apache-airflow[gcp_api]) (2019.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from zope.deprecation<5.0,>=4.0->apache-airflow[gcp_api]) (41.0.1)\n",
      "Requirement already satisfied: wtforms in /usr/local/lib/python3.5/dist-packages (from flask-admin==1.5.3->apache-airflow[gcp_api]) (2.2.1)\n",
      "Requirement already satisfied: docutils in /usr/local/lib/python3.5/dist-packages (from python-daemon<2.2,>=2.1.1->apache-airflow[gcp_api]) (0.15.2)\n",
      "Requirement already satisfied: lockfile>=0.10 in /usr/local/lib/python3.5/dist-packages (from python-daemon<2.2,>=2.1.1->apache-airflow[gcp_api]) (0.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.5/dist-packages (from jinja2<2.11.0,>=2.10.1->apache-airflow[gcp_api]) (1.1.1)\n",
      "Requirement already satisfied: colorama<1,>=0.3.9 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (0.4.1)\n",
      "Requirement already satisfied: marshmallow<2.20,>=2.18.0 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (2.19.5)\n",
      "Requirement already satisfied: Flask-OpenID<2,>=1.2.5 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (1.2.5)\n",
      "Requirement already satisfied: marshmallow-sqlalchemy>=0.16.1<1 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (0.17.0)\n",
      "Requirement already satisfied: Flask-SQLAlchemy<3,>=2.3 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (2.4.0)\n",
      "Requirement already satisfied: apispec[yaml]>=1.1.1<2 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (2.0.2)\n",
      "Requirement already satisfied: PyJWT>=1.7.1 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (1.7.1)\n",
      "Requirement already satisfied: Flask-JWT-Extended<4,>=3.18 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (3.21.0)\n",
      "Requirement already satisfied: Flask-Babel<1,>=0.11.1 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (0.12.2)\n",
      "Requirement already satisfied: jsonschema>=3.0.1<4 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (3.0.1)\n",
      "Requirement already satisfied: prison==0.1.0 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (0.1.0)\n",
      "Requirement already satisfied: marshmallow-enum<2,>=1.4.1 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (1.4.1)\n",
      "Requirement already satisfied: click<8,>=6.7 in /usr/local/lib/python3.5/dist-packages (from flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (7.0)\n",
      "Requirement already satisfied: ordereddict in /usr/local/lib/python3.5/dist-packages (from funcsigs==1.0.0->apache-airflow[gcp_api]) (1.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from pandas<1.0.0,>=0.17.1->apache-airflow[gcp_api]) (1.16.3)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.5/dist-packages (from flask-swagger==0.2.13->apache-airflow[gcp_api]) (3.13)\n",
      "Requirement already satisfied: pytzdata>=2018.3.0.0 in /usr/local/lib/python3.5/dist-packages (from pendulum==1.4.4->apache-airflow[gcp_api]) (2019.2)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.5/dist-packages (from alembic<2.0,>=1.0->apache-airflow[gcp_api]) (1.1.0)\n",
      "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.5/dist-packages (from alembic<2.0,>=1.0->apache-airflow[gcp_api]) (1.0.4)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.5/dist-packages (from flask<2.0,>=1.1.0->apache-airflow[gcp_api]) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.5/dist-packages (from flask<2.0,>=1.1.0->apache-airflow[gcp_api]) (0.15.2)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.5/dist-packages (from google-api-python-client<2.0.0dev,>=1.6.0; extra == \"gcp_api\"->apache-airflow[gcp_api]) (3.0.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.5/dist-packages (from google-cloud-videointelligence>=1.7.0; extra == \"gcp_api\"->apache-airflow[gcp_api]) (1.14.2)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.5/dist-packages (from pandas-gbq; extra == \"gcp_api\"->apache-airflow[gcp_api]) (0.4.0)\n",
      "Requirement already satisfied: google-cloud-bigquery>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from pandas-gbq; extra == \"gcp_api\"->apache-airflow[gcp_api]) (1.18.0)\n",
      "Requirement already satisfied: pydata-google-auth in /usr/local/lib/python3.5/dist-packages (from pandas-gbq; extra == \"gcp_api\"->apache-airflow[gcp_api]) (0.1.3)\n",
      "Requirement already satisfied: cryptography>=2.3 in /usr/local/lib/python3.5/dist-packages (from PyOpenSSL; extra == \"gcp_api\"->apache-airflow[gcp_api]) (2.7)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.5/dist-packages (from google-cloud-storage~=1.16; extra == \"gcp_api\"->apache-airflow[gcp_api]) (1.0.3)\n",
      "Requirement already satisfied: google-resumable-media>=0.3.1 in /usr/local/lib/python3.5/dist-packages (from google-cloud-storage~=1.16; extra == \"gcp_api\"->apache-airflow[gcp_api]) (0.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.5/dist-packages (from google-auth<2.0.0dev,>=1.0.0; extra == \"gcp_api\"->apache-airflow[gcp_api]) (0.2.6)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.5/dist-packages (from google-auth<2.0.0dev,>=1.0.0; extra == \"gcp_api\"->apache-airflow[gcp_api]) (4.0)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.5/dist-packages (from google-auth<2.0.0dev,>=1.0.0; extra == \"gcp_api\"->apache-airflow[gcp_api]) (3.1.1)\n",
      "Collecting grpc-google-iam-v1<0.13dev,>=0.12.3 (from google-cloud-container>=0.1.1; extra == \"gcp_api\"->apache-airflow[gcp_api])\n",
      "  Downloading https://files.pythonhosted.org/packages/65/19/2060c8faa325fddc09aa67af98ffcb6813f39a0ad805679fa64815362b3a/grpc-google-iam-v1-0.12.3.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grpcio>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from grpcio-gcp>=0.2.2; extra == \"gcp_api\"->apache-airflow[gcp_api]) (1.20.1)\n",
      "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-model-analysis<0.14,>=0.13.2->tfx) (1.1.0)\n",
      "Requirement already satisfied: jupyter<2,>=1 in /usr/local/lib/python3.5/dist-packages (from tensorflow-model-analysis<0.14,>=0.13.2->tfx) (1.0.0)\n",
      "Requirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.5/dist-packages (from tensorflow-model-analysis<0.14,>=0.13.2->tfx) (7.4.2)\n",
      "Requirement already satisfied: tensorflow-metadata<0.14,>=0.12.1 in /usr/local/lib/python3.5/dist-packages (from tensorflow-transform<0.14,>=0.13->tfx) (0.13.0)\n",
      "Requirement already satisfied: pydot<1.3,>=1.2.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-transform<0.14,>=0.13->tfx) (1.2.4)\n",
      "Requirement already satisfied: joblib<1,>=0.12 in /usr/local/lib/python3.5/dist-packages (from tensorflow-data-validation<0.14,>=0.13.1->tfx) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn<1,>=0.18 in /usr/local/lib/python3.5/dist-packages (from tensorflow-data-validation<0.14,>=0.13.1->tfx) (0.21.3)\n",
      "Requirement already satisfied: IPython>=5.0 in /usr/local/lib/python3.5/dist-packages (from tensorflow-data-validation<0.14,>=0.13.1->tfx) (7.5.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (1.7)\n",
      "Requirement already satisfied: fastavro<0.22,>=0.21.4 in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (0.21.24)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (2.0.0)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (3.8.0)\n",
      "Requirement already satisfied: pyarrow<0.15.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\" in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (0.14.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (2.5.8)\n",
      "Requirement already satisfied: avro-python3<2.0.0,>=1.8.1; python_version >= \"3.0\" in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (1.9.0)\n",
      "Requirement already satisfied: oauth2client<4,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (3.0.0)\n",
      "Requirement already satisfied: google-cloud-pubsub<0.40.0,>=0.39.0; extra == \"gcp\" in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (0.39.1)\n",
      "Requirement already satisfied: google-apitools<0.5.29,>=0.5.28; extra == \"gcp\" in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (0.5.28)\n",
      "Requirement already satisfied: google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\" in /usr/local/lib/python3.5/dist-packages (from apache-beam[gcp]<3,>=2.12->tfx) (1.7.4)\n",
      "Requirement already satisfied: python3-openid>=2.0 in /usr/local/lib/python3.5/dist-packages (from Flask-OpenID<2,>=1.2.5->flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (3.1.0)\n",
      "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.5/dist-packages (from Flask-Babel<1,>=0.11.1->flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (2.7.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.5/dist-packages (from jsonschema>=3.0.1<4->flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.5/dist-packages (from jsonschema>=3.0.1<4->flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (0.15.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.5/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-videointelligence>=1.7.0; extra == \"gcp_api\"->apache-airflow[gcp_api]) (1.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.5/dist-packages (from google-auth-oauthlib->pandas-gbq; extra == \"gcp_api\"->apache-airflow[gcp_api]) (1.2.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.5/dist-packages (from cryptography>=2.3->PyOpenSSL; extra == \"gcp_api\"->apache-airflow[gcp_api]) (1.12.3)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /usr/local/lib/python3.5/dist-packages (from cryptography>=2.3->PyOpenSSL; extra == \"gcp_api\"->apache-airflow[gcp_api]) (0.24.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.5/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0.0dev,>=1.0.0; extra == \"gcp_api\"->apache-airflow[gcp_api]) (0.4.6)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.5/dist-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (5.5.0)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.5/dist-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (6.0.0)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.5/dist-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (5.1.0)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.5/dist-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (5.7.8)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.5/dist-packages (from jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (4.4.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.5/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (4.3.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.5/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (3.4.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.5/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.5/dist-packages (from pydot<1.3,>=1.2.0->tensorflow-transform<0.14,>=0.13->tfx) (2.4.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.5/dist-packages (from IPython>=5.0->tensorflow-data-validation<0.14,>=0.13.1->tfx) (2.0.9)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.5/dist-packages (from IPython>=5.0->tensorflow-data-validation<0.14,>=0.13.1->tfx) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.5/dist-packages (from IPython>=5.0->tensorflow-data-validation<0.14,>=0.13.1->tfx) (0.7.5)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.5/dist-packages (from IPython>=5.0->tensorflow-data-validation<0.14,>=0.13.1->tfx) (4.4.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.5/dist-packages (from IPython>=5.0->tensorflow-data-validation<0.14,>=0.13.1->tfx) (0.13.3)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.5/dist-packages (from IPython>=5.0->tensorflow-data-validation<0.14,>=0.13.1->tfx) (4.7.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.5/dist-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<3,>=2.12->tfx) (5.2.0)\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.5/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.12->tfx) (0.6.2)\n",
      "Requirement already satisfied: fasteners>=0.14 in /usr/local/lib/python3.5/dist-packages (from google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.12->tfx) (0.15)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.5/dist-packages (from python3-openid>=2.0->Flask-OpenID<2,>=1.2.5->flask-appbuilder<2.0.0,>=1.12.5->apache-airflow[gcp_api]) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.5/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq; extra == \"gcp_api\"->apache-airflow[gcp_api]) (3.1.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.5/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3->PyOpenSSL; extra == \"gcp_api\"->apache-airflow[gcp_api]) (2.19)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.5/dist-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (0.8.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.5/dist-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (0.4.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.5/dist-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (3.1.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.5/dist-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (0.3)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.5/dist-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (4.4.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.5/dist-packages (from nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (1.4.2)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.5/dist-packages (from jupyter-console->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (5.2.4)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.5/dist-packages (from ipykernel->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (6.0.2)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.5/dist-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (0.8.2)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.5/dist-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (0.6.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.5/dist-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (18.0.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.5/dist-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (1.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.5/dist-packages (from notebook->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.5/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython>=5.0->tensorflow-data-validation<0.14,>=0.13.1->tfx) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.3.0 in /usr/local/lib/python3.5/dist-packages (from jedi>=0.10->IPython>=5.0->tensorflow-data-validation<0.14,>=0.13.1->tfx) (0.4.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.5/dist-packages (from pexpect; sys_platform != \"win32\"->IPython>=5.0->tensorflow-data-validation<0.14,>=0.13.1->tfx) (0.6.0)\n",
      "Requirement already satisfied: monotonic>=0.1 in /usr/local/lib/python3.5/dist-packages (from fasteners>=0.14->google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"->apache-beam[gcp]<3,>=2.12->tfx) (1.5)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.5/dist-packages (from bleach->nbconvert->jupyter<2,>=1->tensorflow-model-analysis<0.14,>=0.13.2->tfx) (0.5.1)\n",
      "Building wheels for collected packages: grpc-google-iam-v1\n",
      "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpc-google-iam-v1: filename=grpc_google_iam_v1-0.12.3-cp35-none-any.whl size=15436 sha256=efa62fc0f26d78c606d12a58ebfe551299a90f453cba945398f49bac0361dc05\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/3a/83/77a1e18e1a8757186df834b86ce6800120ac9c79cd8ca4091b\n",
      "Successfully built grpc-google-iam-v1\n",
      "\u001b[31mERROR: google-cloud-spanner 1.9.0 has requirement grpc-google-iam-v1<0.12dev,>=0.11.4, but you'll have grpc-google-iam-v1 0.12.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-cloud-bigtable 0.33.0 has requirement grpc-google-iam-v1<0.12dev,>=0.11.4, but you'll have grpc-google-iam-v1 0.12.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-cloud-pubsub 0.39.1 has requirement grpc-google-iam-v1<0.12dev,>=0.11.4, but you'll have grpc-google-iam-v1 0.12.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: grpc-google-iam-v1\n",
      "  Found existing installation: grpc-google-iam-v1 0.11.4\n",
      "    Uninstalling grpc-google-iam-v1-0.11.4:\n",
      "      Successfully uninstalled grpc-google-iam-v1-0.11.4\n",
      "Successfully installed grpc-google-iam-v1-0.12.3\n"
     ]
    }
   ],
   "source": [
    "!pip install 'apache-airflow[gcp_api]' docker tfx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use TFX version 0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tfx\n",
    "tfx.version.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFX requires TensorFlow >= 1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFX supports Python 3.5 from version 0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.2 (default, Nov 12 2018, 13:43:14) \\n[GCC 5.4.0 20160609]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2019-08-10 05:26:26--  https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.108.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1922668 (1.8M) [text/plain]\n",
      "Saving to: ‘/root/taxi/data/simple/data.csv’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  2% 4.97M 0s\n",
      "    50K .......... .......... .......... .......... ..........  5% 9.73M 0s\n",
      "   100K .......... .......... .......... .......... ..........  7% 10.1M 0s\n",
      "   150K .......... .......... .......... .......... .......... 10% 8.56M 0s\n",
      "   200K .......... .......... .......... .......... .......... 13% 8.86M 0s\n",
      "   250K .......... .......... .......... .......... .......... 15% 7.96M 0s\n",
      "   300K .......... .......... .......... .......... .......... 18% 11.5M 0s\n",
      "   350K .......... .......... .......... .......... .......... 21% 7.85M 0s\n",
      "   400K .......... .......... .......... .......... .......... 23% 17.1M 0s\n",
      "   450K .......... .......... .......... .......... .......... 26% 9.25M 0s\n",
      "   500K .......... .......... .......... .......... .......... 29% 8.26M 0s\n",
      "   550K .......... .......... .......... .......... .......... 31% 11.6M 0s\n",
      "   600K .......... .......... .......... .......... .......... 34% 16.5M 0s\n",
      "   650K .......... .......... .......... .......... .......... 37% 8.92M 0s\n",
      "   700K .......... .......... .......... .......... .......... 39% 13.9M 0s\n",
      "   750K .......... .......... .......... .......... .......... 42% 15.3M 0s\n",
      "   800K .......... .......... .......... .......... .......... 45% 11.6M 0s\n",
      "   850K .......... .......... .......... .......... .......... 47% 2.32M 0s\n",
      "   900K .......... .......... .......... .......... .......... 50% 14.1M 0s\n",
      "   950K .......... .......... .......... .......... .......... 53% 10.6M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 55% 19.2M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 58% 21.6M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 61% 11.3M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 63% 9.66M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 66% 15.2M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 69% 11.3M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 71% 11.0M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 74% 10.6M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 77% 27.1M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 79% 15.3M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 82% 26.3M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 85% 14.9M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 87% 25.8M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 90% 15.1M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 93% 8.39M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 95% 37.1M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 98% 46.0M 0s\n",
      "  1850K .......... .......... .......                         100% 9.84M=0.2s\n",
      "\n",
      "2019-08-10 05:26:27 (10.7 MB/s) - ‘/root/taxi/data/simple/data.csv’ saved [1922668/1922668]\n",
      "\n",
      "--2019-08-10 05:26:27--  https://raw.githubusercontent.com/tensorflow/tfx/r0.13/tfx/examples/chicago_taxi_pipeline/taxi_utils.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.108.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12772 (12K) [text/plain]\n",
      "Saving to: ‘/root/taxi/taxi_utils.py’\n",
      "\n",
      "     0K .......... ..                                         100% 7.13M=0.002s\n",
      "\n",
      "2019-08-10 05:26:27 (7.13 MB/s) - ‘/root/taxi/taxi_utils.py’ saved [12772/12772]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# This enables you to run this notebook twice.\n",
    "# There should not be train/eval files at ~/taxi/data, since TFX can handle only single file with version 0.13.0\n",
    "if [ -e ~/taxi/data ]; then\n",
    "    rm -rf ~/taxi/data\n",
    "fi\n",
    "\n",
    "# download taxi data\n",
    "mkdir -p ~/taxi/data/simple\n",
    "mkdir -p ~/taxi/serving_model/taxi_simple\n",
    "wget https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/chicago_taxi_pipeline/data/simple/data.csv -O ~/taxi/data/simple/data.csv\n",
    "\n",
    "# download \n",
    "wget https://raw.githubusercontent.com/tensorflow/tfx/r0.13/tfx/examples/chicago_taxi_pipeline/taxi_utils.py -O ~/taxi/taxi_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/apache_beam/__init__.py:84: UserWarning: Some syntactic constructs of Python 3 are not yet fully supported by Apache Beam.\n",
      "  'Some syntactic constructs of Python 3 are not yet fully supported by '\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "from google.protobuf import json_format\n",
    "\n",
    "from tfx.components.base.base_component import ComponentOutputs\n",
    "from tfx.components.evaluator.component import Evaluator\n",
    "from tfx.components.example_gen.csv_example_gen.component import CsvExampleGen\n",
    "from tfx.components.example_validator.component import ExampleValidator\n",
    "from tfx.components.model_validator.component import ModelValidator\n",
    "from tfx.components.pusher.component import Pusher\n",
    "from tfx.components.schema_gen.component import SchemaGen\n",
    "from tfx.components.statistics_gen.component import StatisticsGen\n",
    "from tfx.components.trainer.component import Trainer\n",
    "from tfx.components.transform.component import Transform\n",
    "from tfx.orchestration.airflow.airflow_runner import AirflowDAGRunner\n",
    "from tfx.orchestration.pipeline import Pipeline\n",
    "from tfx.orchestration.tfx_runner import TfxRunner\n",
    "from tfx.proto import evaluator_pb2\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "from tfx.utils.dsl_utils import csv_input\n",
    "from tfx.utils.channel import Channel\n",
    "from tfx.utils import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This example assumes that the taxi data is stored in ~/taxi/data and the\n",
    "# taxi utility function is in ~/taxi.  Feel free to customize this as needed.\n",
    "_taxi_root = os.path.join(os.environ['HOME'], 'taxi')\n",
    "_data_root = os.path.join(_taxi_root, 'data/simple')\n",
    "# Python module file to inject customized logic into the TFX components. The\n",
    "# Transform and Trainer both require user-defined functions to run successfully.\n",
    "_taxi_module_file = os.path.join(_taxi_root, 'taxi_utils.py')\n",
    "\n",
    "# Path which can be listened to by the model server.  Pusher will output the\n",
    "# trained model here.\n",
    "_serving_model_dir = os.path.join(_taxi_root, 'serving_model/taxi_simple')\n",
    "\n",
    "# Directory and data locations.  This example assumes all of the chicago taxi\n",
    "# example code and metadata library is relative to $HOME, but you can store\n",
    "# these files anywhere on your local filesystem.\n",
    "_tfx_root = os.path.join(os.environ['HOME'], 'tfx')\n",
    "_pipeline_root = os.path.join(_tfx_root, 'pipelines')\n",
    "_metadata_db_root = os.path.join(_tfx_root, 'metadata')\n",
    "_log_root = os.path.join(_tfx_root, 'logs')\n",
    "\n",
    "# Airflow-specific configs; these will be passed directly to airflow\n",
    "_airflow_config = {\n",
    "    'schedule_interval': None,\n",
    "    'start_date': datetime.datetime(2019, 1, 1),\n",
    "}\n",
    "\n",
    "# Logging overrides\n",
    "logger_overrides = {'log_root': _log_root, 'log_level': logging.INFO}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ExampleGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Implements the chicago taxi pipeline with TFX.\"\"\"\n",
    "examples = csv_input(_data_root)\n",
    "\n",
    "# Brings data into the pipeline or otherwise joins/converts training data.\n",
    "train_config = example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=2)\n",
    "eval_config = example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "output_config = example_gen_pb2.Output(\n",
    "    split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "        train_config,\n",
    "        eval_config\n",
    "    ]))\n",
    "\n",
    "# Create outputs\n",
    "train_examples = types.TfxType(type_name='ExamplesPath', split='train')\n",
    "train_examples.uri = os.path.join(_data_root, 'csv_example_gen/train/')\n",
    "\n",
    "eval_examples = types.TfxType(type_name='ExamplesPath', split='eval')\n",
    "eval_examples.uri = os.path.join(_data_root, 'csv_example_gen/eval/')\n",
    "\n",
    "example_outputs = ComponentOutputs({\n",
    "    'examples': Channel(\n",
    "        type_name='ExamplesPath',\n",
    "        static_artifact_collection=[train_examples, eval_examples]\n",
    "    ),\n",
    "    'training_examples': Channel(\n",
    "        type_name='ExamplesPath',\n",
    "        static_artifact_collection=[train_examples]\n",
    "    ),\n",
    "    'eval_examples': Channel(\n",
    "        type_name='ExamplesPath',\n",
    "        static_artifact_collection=[eval_examples]\n",
    "    ),    \n",
    "})\n",
    "\n",
    "example_gen = CsvExampleGen(\n",
    "    input_base=examples, # A Channel of 'ExternalPath' type, it contains path of data source.\n",
    "    output_config=output_config,  # An example_gen_pb2.Output instance, it contains train-eval split ratio.\n",
    "    outputs=example_outputs # dict from name to output channel, it will be stored example_gen.outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create StatisticsGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create outputs\n",
    "train_statistics = types.TfxType(type_name='ExampleStatisticsPath', split='train')\n",
    "train_statistics.uri = os.path.join(_data_root, 'statistics_gen/train/')\n",
    "\n",
    "eval_statistics = types.TfxType(type_name='ExampleStatisticsPath', split='eval')\n",
    "eval_statistics.uri = os.path.join(_data_root, 'statistics_gen/eval/')\n",
    "\n",
    "statistics_outputs = ComponentOutputs({\n",
    "    'output': Channel(\n",
    "        type_name='ExampleStatisticsPath',\n",
    "        static_artifact_collection=[train_statistics, eval_statistics]\n",
    "    )\n",
    "})\n",
    "\n",
    "statistics_gen = StatisticsGen(\n",
    "    input_data=example_gen.outputs.examples, # A Channel of 'ExamplesPath' type, it is equal to example_outputs\n",
    "    name='Statistics Generator', # Optional, name should be unique if you are going to use multiple StatisticsGen in same pipeline.\n",
    "    outputs=statistics_outputs # dict from name to output channel, it will be stored statistics_gen.outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SchemaGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create outputs\n",
    "train_schema_path = types.TfxType(type_name='SchemaPath', split='train')\n",
    "train_schema_path.uri = os.path.join(_data_root, 'schema_gen/')\n",
    "\n",
    "# NOTE: SchemaGen.executor can handle JUST ONE SchemaPath.\n",
    "# Two or more SchemaPaths will cause ValueError\n",
    "# such as \"ValueError: expected list length of one but got 2\".\n",
    "schema_outputs = ComponentOutputs({\n",
    "    'output':Channel(\n",
    "        type_name='SchemaPath',\n",
    "        static_artifact_collection=[train_schema_path] \n",
    "    )\n",
    "})\n",
    "\n",
    "infer_schema = SchemaGen(\n",
    "    stats=statistics_gen.outputs.output, # A Channel of 'ExampleStatisticsPath' type, it is equal to statistics_outputs\n",
    "    name='Schema Generator',  # Optional, name should be unique if you are going to use multiple StatisticsGen in same pipeline.\n",
    "    outputs=schema_outputs # dict from name to output channel, it will be stored schema_gen.outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_examples = types.TfxType(type_name='ExamplesPath', split='train')\n",
    "train_examples.uri = os.path.join(_data_root,\n",
    "                                  'transform/transformed_examples/train/')\n",
    "eval_examples = types.TfxType(type_name='ExamplesPath', split='eval')\n",
    "eval_examples.uri = os.path.join(_data_root,\n",
    "                                 'transform/transformed_examples/eval/')\n",
    "transform_output = types.TfxType(type_name='TransformPath')\n",
    "transform_output.uri = os.path.join(_data_root,\n",
    "                                    'transform/transform_output/')\n",
    "\n",
    "transform_outputs = ComponentOutputs({\n",
    "    # Output of 'tf.Transform', which includes an exported \n",
    "    # Tensorflow graph suitable for both training and serving\n",
    "    'transform_output':Channel(\n",
    "        type_name='TransformPath',\n",
    "        static_artifact_collection=[transform_output]\n",
    "    ),\n",
    "    # transformed_examples: Materialized transformed examples, which includes \n",
    "    # both 'train' and 'eval' splits.\n",
    "    'transformed_examples':Channel(\n",
    "        type_name='ExamplesPath',\n",
    "        static_artifact_collection=[train_examples, eval_examples]\n",
    "    )\n",
    "})\n",
    "\n",
    "transform = Transform(\n",
    "    input_data=example_gen.outputs.examples,\n",
    "    schema=infer_schema.outputs.output,\n",
    "    module_file=_taxi_module_file,\n",
    "    outputs=transform_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_exports = types.TfxType(type_name='ModelExportPath')\n",
    "model_exports.uri = os.path.join(_data_root, 'trainer/current/')\n",
    "\n",
    "trainer_outputs = ComponentOutputs({\n",
    "    'output':Channel(\n",
    "        type_name='ModelExportPath',\n",
    "        static_artifact_collection=[model_exports]\n",
    "    )\n",
    "})\n",
    "\n",
    "trainer = Trainer(\n",
    "    module_file=_taxi_module_file,\n",
    "    transformed_examples=transform.outputs.transformed_examples,\n",
    "    schema=infer_schema.outputs.output,\n",
    "    transform_output=transform.outputs.transform_output,\n",
    "    train_args=trainer_pb2.TrainArgs(num_steps=10000),\n",
    "    eval_args=trainer_pb2.EvalArgs(num_steps=5000),\n",
    "    outputs=trainer_outputs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_output = types.TfxType('ModelEvalPath')\n",
    "eval_output.uri = os.path.join(_data_root, 'eval_output/')\n",
    "\n",
    "model_analyzer_outputs = ComponentOutputs({\n",
    "    'output':\n",
    "    Channel(\n",
    "        type_name='ModelEvalPath',\n",
    "        static_artifact_collection=[eval_output]),\n",
    "})\n",
    "\n",
    "feature_slicing_spec = evaluator_pb2.FeatureSlicingSpec(specs=[\n",
    "    evaluator_pb2.SingleSlicingSpec(\n",
    "        column_for_slicing=['trip_start_hour'])\n",
    "])\n",
    "\n",
    "model_analyzer = Evaluator(\n",
    "    examples=example_gen.outputs.examples,\n",
    "    model_exports=trainer.outputs.output,\n",
    "    feature_slicing_spec=feature_slicing_spec,\n",
    "    outputs=model_analyzer_outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _Do(self, input_dict, output_dict, exec_properties):\n",
    "    import apache_beam as beam\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_model_analysis as tfma\n",
    "    from typing import Any, Dict, List, Text\n",
    "    from tfx.components.base import base_executor\n",
    "    from tfx.proto import evaluator_pb2\n",
    "    from tfx.utils import io_utils\n",
    "    from tfx.utils import path_utils\n",
    "    from tfx.utils import types\n",
    "    from google.protobuf import json_format\n",
    "\n",
    "    \"\"\"Runs a batch job to evaluate the eval_model against the given input.\n",
    "    Args:\n",
    "      input_dict: Input dict from input key to a list of Artifacts.\n",
    "        - model_exports: exported model.\n",
    "        - examples: examples for eval the model.\n",
    "      output_dict: Output dict from output key to a list of Artifacts.\n",
    "        - output: model evaluation results.\n",
    "      exec_properties: A dict of execution properties.\n",
    "        - feature_slicing_spec: JSON string of evaluator_pb2.FeatureSlicingSpec\n",
    "          instance, providing the way to slice the data.\n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "    if 'model_exports' not in input_dict:\n",
    "      raise ValueError('\\'model_exports\\' is missing in input dict.')\n",
    "    if 'examples' not in input_dict:\n",
    "      raise ValueError('\\'examples\\' is missing in input dict.')\n",
    "    if 'output' not in output_dict:\n",
    "      raise ValueError('\\'output\\' is missing in output dict.')\n",
    "\n",
    "    self._log_startup(input_dict, output_dict, exec_properties)\n",
    "\n",
    "    # Extract input artifacts\n",
    "    model_exports_uri = types.get_single_uri(input_dict['model_exports'])\n",
    "\n",
    "    feature_slicing_spec = evaluator_pb2.FeatureSlicingSpec()\n",
    "    json_format.Parse(exec_properties['feature_slicing_spec'],\n",
    "                      feature_slicing_spec)\n",
    "    slice_spec = self._get_slice_spec_from_feature_slicing_spec(\n",
    "        feature_slicing_spec)\n",
    "\n",
    "    output_uri = types.get_single_uri(output_dict['output'])\n",
    "\n",
    "    eval_model_path = path_utils.eval_model_path(model_exports_uri)\n",
    "\n",
    "    tf.logging.info('Using {} for model eval.'.format(eval_model_path))\n",
    "    eval_shared_model = tfma.default_eval_shared_model(\n",
    "        add_metrics_callbacks=[\n",
    "                        # calibration_plot_and_prediction_histogram computes calibration plot and prediction\n",
    "                        # distribution at different thresholds.\n",
    "                        tfma.post_export_metrics.calibration_plot_and_prediction_histogram(),\n",
    "                        # auc_plots enables precision-recall curve and ROC visualization at different thresholds.\n",
    "                        tfma.post_export_metrics.auc_plots()\n",
    "                    ],\n",
    "        eval_saved_model_path=eval_model_path)\n",
    "\n",
    "    tf.logging.info('Evaluating model.')\n",
    "    with beam.Pipeline(argv=self._get_beam_pipeline_args()) as pipeline:\n",
    "      # pylint: disable=expression-not-assigned\n",
    "      (pipeline\n",
    "       | 'ReadData' >> beam.io.ReadFromTFRecord(\n",
    "           file_pattern=io_utils.all_files_pattern(\n",
    "               types.get_split_uri(input_dict['examples'], 'eval')))\n",
    "       |\n",
    "       'ExtractEvaluateAndWriteResults' >> tfma.ExtractEvaluateAndWriteResults(\n",
    "           eval_shared_model=eval_shared_model,\n",
    "           slice_spec=slice_spec,\n",
    "           output_path=output_uri))\n",
    "    tf.logging.info(\n",
    "        'Evaluation complete. Results written to {}.'.format(output_uri))\n",
    "\n",
    "model_analyzer.executor.Do = _Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    pipeline_name=\"TFX Pipeline\",\n",
    "    pipeline_root=_pipeline_root,\n",
    "    components=[example_gen, statistics_gen, infer_schema, transform, trainer, model_analyzer]\n",
    "#     components=[model_analyzer]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectRunner(TfxRunner):\n",
    "    \"\"\"Tfx runner on local\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        self._config = config or {}\n",
    "    \n",
    "    def run(self, pipeline):\n",
    "        for component in pipeline.components:\n",
    "            self._execute_component(component)\n",
    "            \n",
    "        return pipeline\n",
    "            \n",
    "    def _execute_component(self, component):\n",
    "        input_dict = {key:value.get() for key, value in component.input_dict.items()}\n",
    "        output_dict = {key: value.get() for key, value in component.outputs.get_all().items()}\n",
    "        exec_properties = component.exec_properties\n",
    "        executor = component.executor()\n",
    "        executor.Do(input_dict, output_dict, exec_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting Executor execution.\n",
      "[2019-08-10 05:26:30,374] {base_executor.py:72} INFO - Starting Executor execution.\n",
      "INFO:tensorflow:Inputs for Executor is: {\"input-base\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExternalPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple\"}, \"artifact_type\": {\"name\": \"ExternalPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "[2019-08-10 05:26:30,381] {base_executor.py:74} INFO - Inputs for Executor is: {\"input-base\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExternalPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple\"}, \"artifact_type\": {\"name\": \"ExternalPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "INFO:tensorflow:Outputs for Executor is: {\"eval_examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"training_examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "[2019-08-10 05:26:30,385] {base_executor.py:76} INFO - Outputs for Executor is: {\"eval_examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"training_examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "INFO:tensorflow:Execution properties for Executor is: {\"output\": \"{\\n  \\\"splitConfig\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"name\\\": \\\"train\\\",\\n        \\\"hashBuckets\\\": 2\\n      },\\n      {\\n        \\\"name\\\": \\\"eval\\\",\\n        \\\"hashBuckets\\\": 1\\n      }\\n    ]\\n  }\\n}\"}\n",
      "[2019-08-10 05:26:30,389] {base_executor.py:78} INFO - Execution properties for Executor is: {\"output\": \"{\\n  \\\"splitConfig\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"name\\\": \\\"train\\\",\\n        \\\"hashBuckets\\\": 2\\n      },\\n      {\\n        \\\"name\\\": \\\"eval\\\",\\n        \\\"hashBuckets\\\": 1\\n      }\\n    ]\\n  }\\n}\"}\n",
      "INFO:tensorflow:Generating examples.\n",
      "[2019-08-10 05:26:30,393] {base_example_gen_executor.py:122} INFO - Generating examples.\n",
      "[2019-08-10 05:26:30,398] {pipeline.py:143} INFO - Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
      "INFO:tensorflow:Processing input csv data /root/taxi/data/simple/data.csv to TFExample.\n",
      "[2019-08-10 05:26:30,409] {executor.py:70} INFO - Processing input csv data /root/taxi/data/simple/data.csv to TFExample.\n",
      "[2019-08-10 05:26:31,226] {fn_api_runner_transforms.py:488} INFO - ==================== <function annotate_downstream_side_inputs at 0x7f3cd6d6eae8> ====================\n",
      "[2019-08-10 05:26:31,237] {fn_api_runner_transforms.py:488} INFO - ==================== <function fix_side_input_pcoll_coders at 0x7f3cd6d6ebf8> ====================\n",
      "[2019-08-10 05:26:31,246] {fn_api_runner_transforms.py:488} INFO - ==================== <function lift_combiners at 0x7f3cd6d6ec80> ====================\n",
      "[2019-08-10 05:26:31,256] {fn_api_runner_transforms.py:488} INFO - ==================== <function expand_sdf at 0x7f3cd6d6ed08> ====================\n",
      "[2019-08-10 05:26:31,266] {fn_api_runner_transforms.py:488} INFO - ==================== <function expand_gbk at 0x7f3cd6d6ed90> ====================\n",
      "[2019-08-10 05:26:31,281] {fn_api_runner_transforms.py:488} INFO - ==================== <function sink_flattens at 0x7f3cd6d6eea0> ====================\n",
      "[2019-08-10 05:26:31,288] {fn_api_runner_transforms.py:488} INFO - ==================== <function greedily_fuse at 0x7f3cd6d6ef28> ====================\n",
      "[2019-08-10 05:26:31,305] {fn_api_runner_transforms.py:488} INFO - ==================== <function read_to_impulse at 0x7f3cd6d6f048> ====================\n",
      "[2019-08-10 05:26:31,317] {fn_api_runner_transforms.py:488} INFO - ==================== <function impulse_to_input at 0x7f3cd6d6f0d0> ====================\n",
      "[2019-08-10 05:26:31,331] {fn_api_runner_transforms.py:488} INFO - ==================== <function inject_timer_pcollections at 0x7f3cd6d6f268> ====================\n",
      "[2019-08-10 05:26:31,342] {fn_api_runner_transforms.py:488} INFO - ==================== <function sort_stages at 0x7f3cd6d6f2f0> ====================\n",
      "[2019-08-10 05:26:31,350] {fn_api_runner_transforms.py:488} INFO - ==================== <function window_pcollection_coders at 0x7f3cd6d6f378> ====================\n",
      "[2019-08-10 05:26:31,361] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_OutputSplittrain/Write/WriteImpl/DoOnce/Read_40)+(ref_AppliedPTransform_OutputSplittrain/Write/WriteImpl/InitializeWrite_41))+(ref_PCollection_PCollection_24/Write))+(ref_PCollection_PCollection_25/Write)\n",
      "[2019-08-10 05:26:31,386] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_InputSourceToExample/ReadFromText/Read_4)+((((ref_AppliedPTransform_InputSourceToExample/ParseCSV/ParseCSVRecords_6)+((ref_AppliedPTransform_InputSourceToExample/ParseCSV/InferFeatureTypes/KeyWithVoid_8)+(InputSourceToExample/ParseCSV/InferFeatureTypes/CombinePerKey/Precombine)))+(ref_PCollection_PCollection_2/Write))+(InputSourceToExample/ParseCSV/InferFeatureTypes/CombinePerKey/Group/Write))\n",
      "[2019-08-10 05:26:32,372] {fn_api_runner.py:577} INFO - Running (InputSourceToExample/ParseCSV/InferFeatureTypes/CombinePerKey/Group/Read)+(((InputSourceToExample/ParseCSV/InferFeatureTypes/CombinePerKey/Merge)+(InputSourceToExample/ParseCSV/InferFeatureTypes/CombinePerKey/ExtractOutputs))+((ref_AppliedPTransform_InputSourceToExample/ParseCSV/InferFeatureTypes/UnKey_16)+(ref_PCollection_PCollection_8/Write)))\n",
      "[2019-08-10 05:26:32,394] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_InputSourceToExample/ParseCSV/InferFeatureTypes/DoOnce/Read_18)+(ref_AppliedPTransform_InputSourceToExample/ParseCSV/InferFeatureTypes/InjectDefault_19))+(ref_PCollection_PCollection_10/Write)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:26:32,413] {fn_api_runner.py:577} INFO - Running ((ref_PCollection_PCollection_2/Read)+(ref_AppliedPTransform_InputSourceToExample/ParseCSV/CreateInMemoryDict_20))+(((ref_AppliedPTransform_InputSourceToExample/ToTFExample_21)+(((ref_AppliedPTransform_SerializeDeterministically_22)+((((ref_AppliedPTransform_SplitData/ParDo(ApplyPartitionFnFn)/ParDo(ApplyPartitionFnFn)_25)+(ref_AppliedPTransform_ShuffleSpliteval/AddRandomKeys_53))+(ref_AppliedPTransform_ShuffleSplittrain/AddRandomKeys_27))+((ref_AppliedPTransform_ShuffleSpliteval/ReshufflePerKey/Map(reify_timestamps)_55)+(ShuffleSpliteval/ReshufflePerKey/GroupByKey/Write))))+(ref_AppliedPTransform_ShuffleSplittrain/ReshufflePerKey/Map(reify_timestamps)_29)))+(ShuffleSplittrain/ReshufflePerKey/GroupByKey/Write))\n",
      "[2019-08-10 05:26:36,700] {fn_api_runner.py:577} INFO - Running ((ShuffleSplittrain/ReshufflePerKey/GroupByKey/Read)+(ref_AppliedPTransform_ShuffleSplittrain/ReshufflePerKey/FlatMap(restore_timestamps)_34))+((((ref_AppliedPTransform_ShuffleSplittrain/RemoveRandomKeys_35)+((ref_AppliedPTransform_OutputSplittrain/Write/WriteImpl/WriteBundles_42)+(ref_AppliedPTransform_OutputSplittrain/Write/WriteImpl/Pair_43)))+(ref_AppliedPTransform_OutputSplittrain/Write/WriteImpl/WindowInto(WindowIntoFn)_44))+(OutputSplittrain/Write/WriteImpl/GroupByKey/Write))\n",
      "[2019-08-10 05:26:36,834] {tfrecordio.py:57} WARNING - Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "[2019-08-10 05:26:37,164] {fn_api_runner.py:577} INFO - Running ((OutputSplittrain/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_OutputSplittrain/Write/WriteImpl/Extract_49))+(ref_PCollection_PCollection_32/Write)\n",
      "[2019-08-10 05:26:37,179] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_24/Read)+((ref_AppliedPTransform_OutputSplittrain/Write/WriteImpl/PreFinalize_50)+(ref_PCollection_PCollection_33/Write))\n",
      "[2019-08-10 05:26:37,194] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_OutputSpliteval/Write/WriteImpl/DoOnce/Read_66)+((ref_AppliedPTransform_OutputSpliteval/Write/WriteImpl/InitializeWrite_67)+(ref_PCollection_PCollection_43/Write)))+(ref_PCollection_PCollection_42/Write)\n",
      "[2019-08-10 05:26:37,210] {fn_api_runner.py:577} INFO - Running (((ShuffleSpliteval/ReshufflePerKey/GroupByKey/Read)+((ref_AppliedPTransform_ShuffleSpliteval/ReshufflePerKey/FlatMap(restore_timestamps)_60)+(ref_AppliedPTransform_ShuffleSpliteval/RemoveRandomKeys_61)))+((ref_AppliedPTransform_OutputSpliteval/Write/WriteImpl/WriteBundles_68)+((ref_AppliedPTransform_OutputSpliteval/Write/WriteImpl/Pair_69)+(ref_AppliedPTransform_OutputSpliteval/Write/WriteImpl/WindowInto(WindowIntoFn)_70))))+(OutputSpliteval/Write/WriteImpl/GroupByKey/Write)\n",
      "[2019-08-10 05:26:37,442] {fn_api_runner.py:577} INFO - Running (OutputSpliteval/Write/WriteImpl/GroupByKey/Read)+((ref_AppliedPTransform_OutputSpliteval/Write/WriteImpl/Extract_75)+(ref_PCollection_PCollection_50/Write))\n",
      "[2019-08-10 05:26:37,459] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_42/Read)+((ref_AppliedPTransform_OutputSpliteval/Write/WriteImpl/PreFinalize_76)+(ref_PCollection_PCollection_51/Write))\n",
      "[2019-08-10 05:26:37,475] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_42/Read)+(ref_AppliedPTransform_OutputSpliteval/Write/WriteImpl/FinalizeWrite_77)\n",
      "[2019-08-10 05:26:37,488] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "[2019-08-10 05:26:37,598] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n",
      "[2019-08-10 05:26:37,633] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_24/Read)+(ref_AppliedPTransform_OutputSplittrain/Write/WriteImpl/FinalizeWrite_51)\n",
      "[2019-08-10 05:26:37,651] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "[2019-08-10 05:26:37,758] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n",
      "INFO:tensorflow:Examples generated.\n",
      "[2019-08-10 05:26:37,785] {base_example_gen_executor.py:145} INFO - Examples generated.\n",
      "INFO:tensorflow:Starting Executor execution.\n",
      "[2019-08-10 05:26:37,793] {base_executor.py:72} INFO - Starting Executor execution.\n",
      "INFO:tensorflow:Inputs for Executor is: {\"input_data\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "[2019-08-10 05:26:37,800] {base_executor.py:74} INFO - Inputs for Executor is: {\"input_data\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "INFO:tensorflow:Outputs for Executor is: {\"output\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExampleStatisticsPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/statistics_gen/train/\"}, \"artifact_type\": {\"name\": \"ExampleStatisticsPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExampleStatisticsPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/statistics_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExampleStatisticsPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "[2019-08-10 05:26:37,810] {base_executor.py:76} INFO - Outputs for Executor is: {\"output\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExampleStatisticsPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/statistics_gen/train/\"}, \"artifact_type\": {\"name\": \"ExampleStatisticsPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExampleStatisticsPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/statistics_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExampleStatisticsPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "INFO:tensorflow:Execution properties for Executor is: {}\n",
      "[2019-08-10 05:26:37,816] {base_executor.py:78} INFO - Execution properties for Executor is: {}\n",
      "[2019-08-10 05:26:37,824] {pipeline.py:143} INFO - Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
      "INFO:tensorflow:Generating statistics for split eval\n",
      "[2019-08-10 05:26:37,837] {executor.py:62} INFO - Generating statistics for split eval\n",
      "INFO:tensorflow:Generating statistics for split train\n",
      "[2019-08-10 05:26:38,515] {executor.py:62} INFO - Generating statistics for split train\n",
      "INFO:tensorflow:Statistics written to /root/taxi/data/simple/statistics_gen/train/.\n",
      "[2019-08-10 05:26:39,025] {executor.py:78} INFO - Statistics written to /root/taxi/data/simple/statistics_gen/train/.\n",
      "[2019-08-10 05:26:41,351] {fn_api_runner_transforms.py:488} INFO - ==================== <function annotate_downstream_side_inputs at 0x7f3cd6d6eae8> ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:26:41,365] {fn_api_runner_transforms.py:488} INFO - ==================== <function fix_side_input_pcoll_coders at 0x7f3cd6d6ebf8> ====================\n",
      "[2019-08-10 05:26:41,378] {fn_api_runner_transforms.py:488} INFO - ==================== <function lift_combiners at 0x7f3cd6d6ec80> ====================\n",
      "[2019-08-10 05:26:41,397] {fn_api_runner_transforms.py:488} INFO - ==================== <function expand_sdf at 0x7f3cd6d6ed08> ====================\n",
      "[2019-08-10 05:26:41,407] {fn_api_runner_transforms.py:488} INFO - ==================== <function expand_gbk at 0x7f3cd6d6ed90> ====================\n",
      "[2019-08-10 05:26:41,423] {fn_api_runner_transforms.py:488} INFO - ==================== <function sink_flattens at 0x7f3cd6d6eea0> ====================\n",
      "[2019-08-10 05:26:41,437] {fn_api_runner_transforms.py:488} INFO - ==================== <function greedily_fuse at 0x7f3cd6d6ef28> ====================\n",
      "[2019-08-10 05:26:41,457] {fn_api_runner_transforms.py:488} INFO - ==================== <function read_to_impulse at 0x7f3cd6d6f048> ====================\n",
      "[2019-08-10 05:26:41,466] {fn_api_runner_transforms.py:488} INFO - ==================== <function impulse_to_input at 0x7f3cd6d6f0d0> ====================\n",
      "[2019-08-10 05:26:41,479] {fn_api_runner_transforms.py:488} INFO - ==================== <function inject_timer_pcollections at 0x7f3cd6d6f268> ====================\n",
      "[2019-08-10 05:26:41,490] {fn_api_runner_transforms.py:488} INFO - ==================== <function sort_stages at 0x7f3cd6d6f2f0> ====================\n",
      "[2019-08-10 05:26:41,499] {fn_api_runner_transforms.py:488} INFO - ==================== <function window_pcollection_coders at 0x7f3cd6d6f378> ====================\n",
      "[2019-08-10 05:26:41,526] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_WriteStatsOutput.train/Write/WriteImpl/DoOnce/Read_197)+((ref_AppliedPTransform_WriteStatsOutput.train/Write/WriteImpl/InitializeWrite_198)+(ref_PCollection_PCollection_120/Write)))+(ref_PCollection_PCollection_119/Write)\n",
      "[2019-08-10 05:26:41,545] {fn_api_runner.py:577} INFO - Running ((((((ref_AppliedPTransform_ReadData.train/Read_106)+(ref_AppliedPTransform_DecodeData.train/ParseTFExamples_108))+(ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/KeyWithVoid_111))+((((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/ParDo(SplitHotCold)/ParDo(SplitHotCold)_115)+(ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/WindowIntoDiscarding_116))+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PreCombineFn)/Precombine))+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PreCombineFn)/Group/Write)))+((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_ConvertInputToFeatureValuesWithWeights_135)+((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_FlattenToSlicedFeatureNameValueTuples_136)+((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/TopKUniques_CountSlicedFeatureNameValueTuple:PairWithVoid_138)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/CombinePerKey(CountCombineFn)/Precombine)))))+((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/Flatten/Transcode/0)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/Flatten/Write/0)))+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/CombinePerKey(CountCombineFn)/Group/Write)\n",
      "[2019-08-10 05:26:46,446] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PreCombineFn)/Group/Read)+(((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PreCombineFn)/Merge)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PreCombineFn)/ExtractOutputs))+((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/Map(StripNonce)_124)+(ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/WindowIntoOriginal_125))))+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/Flatten/Write/1)\n",
      "[2019-08-10 05:26:46,660] {fn_api_runner.py:577} INFO - Running (GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/Flatten/Read)+((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PostCombineFn)/Precombine)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PostCombineFn)/Group/Write))\n",
      "[2019-08-10 05:26:46,776] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PostCombineFn)/Group/Read)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PostCombineFn)/Merge))+((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PostCombineFn)/ExtractOutputs)+((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Transcode/0)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Write/0)))\n",
      "[2019-08-10 05:26:47,017] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/CombinePerKey(CountCombineFn)/Group/Read)+((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/CombinePerKey(CountCombineFn)/Merge)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/CombinePerKey(CountCombineFn)/ExtractOutputs)))+(((((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_ModifyKeyToSlicedFeatureName_146)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_GetTopK/CombinePerKey(TopCombineFn)/Precombine))+((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_DropValues_156)+(ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/Uniques_CountPerFeatureName:PairWithVoid_158)))+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_GetTopK/CombinePerKey(TopCombineFn)/Group/Write))+((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Precombine)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Group/Write)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:26:47,050] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_GetTopK/CombinePerKey(TopCombineFn)/Group/Read)+((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_GetTopK/CombinePerKey(TopCombineFn)/Merge)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_GetTopK/CombinePerKey(TopCombineFn)/ExtractOutputs)))+((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_ConvertToSingleFeatureStats_155)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesResults/Write/0))\n",
      "[2019-08-10 05:26:47,071] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Group/Read)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Merge))+(((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/ExtractOutputs)+(ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_ConvertToSingleFeatureStats_166))+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesResults/Write/1))\n",
      "[2019-08-10 05:26:47,092] {fn_api_runner.py:577} INFO - Running (GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesResults/Read)+(((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/DeserializeTopKUniquesFeatureStatsProto_168)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Transcode/1))+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Write/1))\n",
      "[2019-08-10 05:26:47,112] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Read)+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/MergeDatasetFeatureStatisticsProtos/Precombine))+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/MergeDatasetFeatureStatisticsProtos/Group/Write)\n",
      "[2019-08-10 05:26:47,133] {fn_api_runner.py:577} INFO - Running ((((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/MergeDatasetFeatureStatisticsProtos/Group/Read)+((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/MergeDatasetFeatureStatisticsProtos/Merge)+((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/MergeDatasetFeatureStatisticsProtos/ExtractOutputs)+(ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/AddSliceKeyToStatsProto_177))))+(ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/KeyWithVoid_180))+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Precombine))+(GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Group/Write)\n",
      "[2019-08-10 05:26:47,162] {fn_api_runner.py:577} INFO - Running (GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Group/Read)+((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Merge)+(((GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/ExtractOutputs)+(ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/UnKey_188))+(ref_PCollection_PCollection_115/Write)))\n",
      "[2019-08-10 05:26:47,186] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/DoOnce/Read_190)+((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/InjectDefault_191)+((ref_AppliedPTransform_GenerateStatistics.train/RunStatsGenerators/GenerateSlicedStatisticsImpl/MakeDatasetFeatureStatisticsListProto_192)+(((ref_AppliedPTransform_WriteStatsOutput.train/Write/WriteImpl/Map(<lambda at iobase.py:989>)_199)+(ref_AppliedPTransform_WriteStatsOutput.train/Write/WriteImpl/WindowInto(WindowIntoFn)_200))+(WriteStatsOutput.train/Write/WriteImpl/GroupByKey/Write))))\n",
      "[2019-08-10 05:26:47,223] {fn_api_runner.py:577} INFO - Running ((WriteStatsOutput.train/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_WriteStatsOutput.train/Write/WriteImpl/WriteBundles_205))+(ref_PCollection_PCollection_126/Write)\n",
      "[2019-08-10 05:26:47,243] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_119/Read)+((ref_AppliedPTransform_WriteStatsOutput.train/Write/WriteImpl/PreFinalize_206)+(ref_PCollection_PCollection_127/Write))\n",
      "[2019-08-10 05:26:47,263] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_119/Read)+(ref_AppliedPTransform_WriteStatsOutput.train/Write/WriteImpl/FinalizeWrite_207)\n",
      "[2019-08-10 05:26:47,280] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "[2019-08-10 05:26:47,387] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n",
      "[2019-08-10 05:26:47,405] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_ReadData.eval/Read_3)+((ref_AppliedPTransform_DecodeData.eval/ParseTFExamples_5)+(((((ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/KeyWithVoid_8)+((ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/ParDo(SplitHotCold)/ParDo(SplitHotCold)_12)+(ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/WindowIntoDiscarding_13)))+(ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_ConvertInputToFeatureValuesWithWeights_32))+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PreCombineFn)/Precombine)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PreCombineFn)/Group/Write)))+(ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_FlattenToSlicedFeatureNameValueTuples_33))))+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/Flatten/Transcode/0)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/Flatten/Write/0)))+(((ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/TopKUniques_CountSlicedFeatureNameValueTuple:PairWithVoid_35)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/CombinePerKey(CountCombineFn)/Precombine))+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/CombinePerKey(CountCombineFn)/Group/Write))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:26:50,082] {fn_api_runner.py:577} INFO - Running ((((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/CombinePerKey(CountCombineFn)/Group/Read)+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/CombinePerKey(CountCombineFn)/Merge)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_CountSlicedFeatureNameValueTuple/CombinePerKey(CountCombineFn)/ExtractOutputs)))+(ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopKUniques_ModifyKeyToSlicedFeatureName_43))+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_GetTopK/CombinePerKey(TopCombineFn)/Precombine)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_GetTopK/CombinePerKey(TopCombineFn)/Group/Write)))+((ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_DropValues_53)+((ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/Uniques_CountPerFeatureName:PairWithVoid_55)+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Precombine)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Group/Write))))\n",
      "[2019-08-10 05:26:50,119] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_GetTopK/CombinePerKey(TopCombineFn)/Group/Read)+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_GetTopK/CombinePerKey(TopCombineFn)/Merge)+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_GetTopK/CombinePerKey(TopCombineFn)/ExtractOutputs)+(ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/TopK_ConvertToSingleFeatureStats_52))))+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesResults/Write/0)\n",
      "[2019-08-10 05:26:50,141] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Group/Read)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/Merge))+(((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_CountPerFeatureName/CombinePerKey(CountCombineFn)/ExtractOutputs)+(ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/Uniques_ConvertToSingleFeatureStats_63))+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesResults/Write/1))\n",
      "[2019-08-10 05:26:50,162] {fn_api_runner.py:577} INFO - Running (GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/FlattenTopKUniquesResults/Read)+(((ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/TopKUniquesStatsGenerator/DeserializeTopKUniquesFeatureStatsProto_65)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Transcode/1))+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Write/1))\n",
      "[2019-08-10 05:26:50,182] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_WriteStatsOutput.eval/Write/WriteImpl/DoOnce/Read_94)+(ref_AppliedPTransform_WriteStatsOutput.eval/Write/WriteImpl/InitializeWrite_95))+(ref_PCollection_PCollection_55/Write))+(ref_PCollection_PCollection_56/Write)\n",
      "[2019-08-10 05:26:50,201] {fn_api_runner.py:577} INFO - Running (((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PreCombineFn)/Group/Read)+(((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PreCombineFn)/Merge)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PreCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/Map(StripNonce)_21)))+(ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/WindowIntoOriginal_22))+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/Flatten/Write/1)\n",
      "[2019-08-10 05:26:50,401] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/Flatten/Read)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PostCombineFn)/Precombine))+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PostCombineFn)/Group/Write)\n",
      "[2019-08-10 05:26:50,509] {fn_api_runner.py:577} INFO - Running (((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PostCombineFn)/Group/Read)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PostCombineFn)/Merge))+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/BasicStatsGenerator/CombinePerKey(PostCombineFn)/ExtractOutputs)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Transcode/0)))+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Write/0)\n",
      "[2019-08-10 05:26:50,731] {fn_api_runner.py:577} INFO - Running (GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/FlattenFeatureStatistics/Read)+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/MergeDatasetFeatureStatisticsProtos/Precombine)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/MergeDatasetFeatureStatisticsProtos/Group/Write))\n",
      "[2019-08-10 05:26:50,746] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/MergeDatasetFeatureStatisticsProtos/Group/Read)+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/MergeDatasetFeatureStatisticsProtos/Merge)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/MergeDatasetFeatureStatisticsProtos/ExtractOutputs)))+((ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/AddSliceKeyToStatsProto_74)+(((ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/KeyWithVoid_77)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Precombine))+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Group/Write)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:26:50,773] {fn_api_runner.py:577} INFO - Running ((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Group/Read)+(GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/Merge))+((GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/CombinePerKey/ExtractOutputs)+((ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/UnKey_85)+(ref_PCollection_PCollection_51/Write)))\n",
      "[2019-08-10 05:26:50,795] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/DoOnce/Read_87)+(((ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/ToList/ToList/InjectDefault_88)+(ref_AppliedPTransform_GenerateStatistics.eval/RunStatsGenerators/GenerateSlicedStatisticsImpl/MakeDatasetFeatureStatisticsListProto_89))+((ref_AppliedPTransform_WriteStatsOutput.eval/Write/WriteImpl/Map(<lambda at iobase.py:989>)_96)+((ref_AppliedPTransform_WriteStatsOutput.eval/Write/WriteImpl/WindowInto(WindowIntoFn)_97)+(WriteStatsOutput.eval/Write/WriteImpl/GroupByKey/Write))))\n",
      "[2019-08-10 05:26:50,827] {fn_api_runner.py:577} INFO - Running (WriteStatsOutput.eval/Write/WriteImpl/GroupByKey/Read)+((ref_AppliedPTransform_WriteStatsOutput.eval/Write/WriteImpl/WriteBundles_102)+(ref_PCollection_PCollection_62/Write))\n",
      "[2019-08-10 05:26:50,847] {fn_api_runner.py:577} INFO - Running ((ref_PCollection_PCollection_55/Read)+(ref_AppliedPTransform_WriteStatsOutput.eval/Write/WriteImpl/PreFinalize_103))+(ref_PCollection_PCollection_63/Write)\n",
      "[2019-08-10 05:26:50,866] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_55/Read)+(ref_AppliedPTransform_WriteStatsOutput.eval/Write/WriteImpl/FinalizeWrite_104)\n",
      "[2019-08-10 05:26:50,882] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "[2019-08-10 05:26:50,988] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n",
      "INFO:tensorflow:Infering schema from statistics.\n",
      "[2019-08-10 05:26:51,015] {executor.py:62} INFO - Infering schema from statistics.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_data_validation/utils/stats_gen_lib.py:328: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "[2019-08-10 05:26:51,022] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow_data_validation/utils/stats_gen_lib.py:328: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "INFO:tensorflow:Schema written to /root/taxi/data/simple/schema_gen/schema.pbtxt.\n",
      "[2019-08-10 05:26:51,081] {executor.py:66} INFO - Schema written to /root/taxi/data/simple/schema_gen/schema.pbtxt.\n",
      "INFO:tensorflow:Starting Executor execution.\n",
      "[2019-08-10 05:26:51,087] {base_executor.py:72} INFO - Starting Executor execution.\n",
      "INFO:tensorflow:Inputs for Executor is: {\"schema\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"SchemaPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/schema_gen/\"}, \"artifact_type\": {\"name\": \"SchemaPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"input_data\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "[2019-08-10 05:26:51,093] {base_executor.py:74} INFO - Inputs for Executor is: {\"schema\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"SchemaPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/schema_gen/\"}, \"artifact_type\": {\"name\": \"SchemaPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"input_data\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "INFO:tensorflow:Outputs for Executor is: {\"transformed_examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/transform/transformed_examples/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/transform/transformed_examples/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"transform_output\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"TransformPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple/transform/transform_output/\"}, \"artifact_type\": {\"name\": \"TransformPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "[2019-08-10 05:26:51,099] {base_executor.py:76} INFO - Outputs for Executor is: {\"transformed_examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/transform/transformed_examples/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/transform/transformed_examples/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"transform_output\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"TransformPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple/transform/transform_output/\"}, \"artifact_type\": {\"name\": \"TransformPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "INFO:tensorflow:Execution properties for Executor is: {\"module_file\": \"/root/taxi/taxi_utils.py\"}\n",
      "[2019-08-10 05:26:51,105] {base_executor.py:78} INFO - Execution properties for Executor is: {\"module_file\": \"/root/taxi/taxi_utils.py\"}\n",
      "INFO:tensorflow:Inputs to executor.Transform function: {'transform_only_data_paths': '/root/taxi/data/simple/csv_example_gen/eval/*', 'analyze_and_transform_data_paths': '/root/taxi/data/simple/csv_example_gen/train/*', 'preprocessing_fn': '/root/taxi/taxi_utils.py', 'examples_data_format': 'FORMAT_TF_EXAMPLE', 'tft_statistics_use_tfdv': True, 'schema_path': '/root/taxi/data/simple/schema_gen/schema.pbtxt', 'compute_statistics': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:26:51,129] {executor.py:567} INFO - Inputs to executor.Transform function: {'transform_only_data_paths': '/root/taxi/data/simple/csv_example_gen/eval/*', 'analyze_and_transform_data_paths': '/root/taxi/data/simple/csv_example_gen/train/*', 'preprocessing_fn': '/root/taxi/taxi_utils.py', 'examples_data_format': 'FORMAT_TF_EXAMPLE', 'tft_statistics_use_tfdv': True, 'schema_path': '/root/taxi/data/simple/schema_gen/schema.pbtxt', 'compute_statistics': False}\n",
      "INFO:tensorflow:Outputs to executor.Transform function: {'transform_output_path': '/root/taxi/data/simple/transform/transform_output/', 'transform_materialize_output_paths': ['/root/taxi/data/simple/transform/transformed_examples/train/transformed_examples', '/root/taxi/data/simple/transform/transformed_examples/eval/transformed_examples'], 'temp_path': '/root/taxi/data/simple/transform/transform_output/.temp_path'}\n",
      "[2019-08-10 05:26:51,134] {executor.py:569} INFO - Outputs to executor.Transform function: {'transform_output_path': '/root/taxi/data/simple/transform/transform_output/', 'transform_materialize_output_paths': ['/root/taxi/data/simple/transform/transformed_examples/train/transformed_examples', '/root/taxi/data/simple/transform/transformed_examples/eval/transformed_examples'], 'temp_path': '/root/taxi/data/simple/transform/transform_output/.temp_path'}\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_transform/mappers.py:1027: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[2019-08-10 05:26:51,244] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow_transform/mappers.py:1027: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Analyze and transform data patterns: [(0, '/root/taxi/data/simple/csv_example_gen/train/*')]\n",
      "[2019-08-10 05:26:51,342] {executor.py:653} INFO - Analyze and transform data patterns: [(0, '/root/taxi/data/simple/csv_example_gen/train/*')]\n",
      "INFO:tensorflow:Transform data patterns: [(0, '/root/taxi/data/simple/csv_example_gen/eval/*')]\n",
      "[2019-08-10 05:26:51,349] {executor.py:655} INFO - Transform data patterns: [(0, '/root/taxi/data/simple/csv_example_gen/eval/*')]\n",
      "INFO:tensorflow:Transform materialization output paths: [(0, '/root/taxi/data/simple/transform/transformed_examples/train/transformed_examples'), (1, '/root/taxi/data/simple/transform/transformed_examples/eval/transformed_examples')]\n",
      "[2019-08-10 05:26:51,356] {executor.py:657} INFO - Transform materialization output paths: [(0, '/root/taxi/data/simple/transform/transformed_examples/train/transformed_examples'), (1, '/root/taxi/data/simple/transform/transformed_examples/eval/transformed_examples')]\n",
      "INFO:tensorflow:Transform output path: /root/taxi/data/simple/transform/transform_output/\n",
      "[2019-08-10 05:26:51,367] {executor.py:658} INFO - Transform output path: /root/taxi/data/simple/transform/transform_output/\n",
      "[2019-08-10 05:26:51,706] {pipeline.py:143} INFO - Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "[2019-08-10 05:26:52,160] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "[2019-08-10 05:26:52,180] {builder_impl.py:654} INFO - Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "[2019-08-10 05:26:52,186] {builder_impl.py:449} INFO - No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /root/taxi/data/simple/transform/transform_output/.temp_path/tftransform_tmp/cd070c2479d24d19b9d164858920f8f2/saved_model.pb\n",
      "[2019-08-10 05:26:52,221] {builder_impl.py:414} INFO - SavedModel written to: /root/taxi/data/simple/transform/transform_output/.temp_path/tftransform_tmp/cd070c2479d24d19b9d164858920f8f2/saved_model.pb\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "[2019-08-10 05:26:53,621] {builder_impl.py:654} INFO - Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "[2019-08-10 05:26:53,627] {builder_impl.py:449} INFO - No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /root/taxi/data/simple/transform/transform_output/.temp_path/tftransform_tmp/484a3fe909834ee086fb3df272fd3dcd/saved_model.pb\n",
      "[2019-08-10 05:26:53,657] {builder_impl.py:414} INFO - SavedModel written to: /root/taxi/data/simple/transform/transform_output/.temp_path/tftransform_tmp/484a3fe909834ee086fb3df272fd3dcd/saved_model.pb\n",
      "[2019-08-10 05:26:57,601] {fn_api_runner_transforms.py:488} INFO - ==================== <function annotate_downstream_side_inputs at 0x7f3cd6d6eae8> ====================\n",
      "[2019-08-10 05:26:57,615] {fn_api_runner_transforms.py:488} INFO - ==================== <function fix_side_input_pcoll_coders at 0x7f3cd6d6ebf8> ====================\n",
      "[2019-08-10 05:26:57,627] {fn_api_runner_transforms.py:488} INFO - ==================== <function lift_combiners at 0x7f3cd6d6ec80> ====================\n",
      "[2019-08-10 05:26:57,642] {fn_api_runner_transforms.py:488} INFO - ==================== <function expand_sdf at 0x7f3cd6d6ed08> ====================\n",
      "[2019-08-10 05:26:57,657] {fn_api_runner_transforms.py:488} INFO - ==================== <function expand_gbk at 0x7f3cd6d6ed90> ====================\n",
      "[2019-08-10 05:26:57,668] {fn_api_runner_transforms.py:488} INFO - ==================== <function sink_flattens at 0x7f3cd6d6eea0> ====================\n",
      "[2019-08-10 05:26:57,682] {fn_api_runner_transforms.py:488} INFO - ==================== <function greedily_fuse at 0x7f3cd6d6ef28> ====================\n",
      "[2019-08-10 05:26:57,711] {fn_api_runner_transforms.py:488} INFO - ==================== <function read_to_impulse at 0x7f3cd6d6f048> ====================\n",
      "[2019-08-10 05:26:57,722] {fn_api_runner_transforms.py:488} INFO - ==================== <function impulse_to_input at 0x7f3cd6d6f0d0> ====================\n",
      "[2019-08-10 05:26:57,736] {fn_api_runner_transforms.py:488} INFO - ==================== <function inject_timer_pcollections at 0x7f3cd6d6f268> ====================\n",
      "[2019-08-10 05:26:57,746] {fn_api_runner_transforms.py:488} INFO - ==================== <function sort_stages at 0x7f3cd6d6f2f0> ====================\n",
      "[2019-08-10 05:26:57,757] {fn_api_runner_transforms.py:488} INFO - ==================== <function window_pcollection_coders at 0x7f3cd6d6f378> ====================\n",
      "[2019-08-10 05:26:57,787] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_ReadAnalysisDataset[0]/Read/Read_4)+(ref_AppliedPTransform_ReadAnalysisDataset[0]/AddKey_5))+((ref_AppliedPTransform_ReadAnalysisDataset[0]/ParseExamples_6)+(ref_AppliedPTransform_DecodeAnalysisDataset[0]/ApplyDecodeFn_8)))+(FlattenAnalysisDatasets/Write/0)\n",
      "[2019-08-10 05:26:59,179] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_AnalyzeDataset/CreateSavedModelForAnalyzerInputs[0]/CreateSavedModel/Read_13)+(ref_PCollection_PCollection_6/Write)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:26:59,198] {fn_api_runner.py:577} INFO - Running ((((((((((FlattenAnalysisDatasets/Read)+(ref_AppliedPTransform_AnalyzeDataset/ApplySavedModel[0]/BatchInputs/BatchElements/ParDo(_GlobalWindowsBatchingDoFn)_17))+((((((((((ref_AppliedPTransform_AnalyzeDataset/ApplySavedModel[0]/ApplySavedModel_18)+((ref_AppliedPTransform_AnalyzeDataset/TensorSource[scale_to_z_score/mean_and_var]_19)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/KeyWithVoid_22)+((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Write)))))+(ref_AppliedPTransform_AnalyzeDataset/TensorSource[scale_to_z_score_1/mean_and_var]_46))+((ref_AppliedPTransform_AnalyzeDataset/TensorSource[scale_to_z_score_2/mean_and_var]_73)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/KeyWithVoid_76)))+((((ref_AppliedPTransform_AnalyzeDataset/TensorSource[compute_and_apply_vocabulary/vocabulary]_100)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/FlattenStringsAndMaybeWeightsLabels_102))+(ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CountPerString:PairWithVoid_104))+((AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Precombine)+(AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Group/Write))))+(ref_AppliedPTransform_AnalyzeDataset/TensorSource[compute_and_apply_vocabulary_1/vocabulary]_158))+((ref_AppliedPTransform_AnalyzeDataset/TensorSource[bucketize/quantiles]_216)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/KeyWithVoid_219)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/CombinePerKey/Precombine))))+(ref_AppliedPTransform_AnalyzeDataset/TensorSource[bucketize_1/quantiles]_248))+((ref_AppliedPTransform_AnalyzeDataset/TensorSource[bucketize_2/quantiles]_280)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/KeyWithVoid_283)))+(((ref_AppliedPTransform_AnalyzeDataset/TensorSource[bucketize_3/quantiles]_312)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/KeyWithVoid_315))+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/CombinePerKey/Precombine))))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/KeyWithVoid_251)+((AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Write))))+(AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Write))+((ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/FlattenStringsAndMaybeWeightsLabels_160)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CountPerString:PairWithVoid_162)))+((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Write)))+((AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Precombine)+(AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Group/Write)))+((AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Write)))+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Write))+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/KeyWithVoid_49)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/CombinePerKey/Precombine))+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Write))\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:26:59,675] {saver.py:1483} INFO - Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:27:00,439] {fn_api_runner.py:577} INFO - Running (AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Read)+((AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/CombinePerKey/Merge)+((AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/CombinePerKey/ExtractOutputs)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/UnKey_227)+(ref_PCollection_PCollection_141/Write))))\n",
      "[2019-08-10 05:27:00,549] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/DoOnce/Read_229)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize/quantiles]/InitialCombineGlobally/InjectDefault_230))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/KeyWithVoid_233))+((AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Write))\n",
      "[2019-08-10 05:27:00,615] {fn_api_runner.py:577} INFO - Running (AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Read)+(((AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/CombinePerKey/Merge)+(AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/UnKey_241)+(ref_PCollection_PCollection_149/Write)))\n",
      "[2019-08-10 05:27:00,713] {fn_api_runner.py:577} INFO - Running ((AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Read)+(((AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/CombinePerKey/Merge)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/UnKey_291)))+(ref_PCollection_PCollection_181/Write)\n",
      "[2019-08-10 05:27:00,811] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/DoOnce/Read_293)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_2/quantiles]/InitialCombineGlobally/InjectDefault_294))+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/KeyWithVoid_297)+(AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/CombinePerKey/Precombine))+(AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Write))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:27:00,877] {fn_api_runner.py:577} INFO - Running (AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Read)+(((AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/CombinePerKey/Merge)+((AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/UnKey_305)))+(ref_PCollection_PCollection_189/Write))\n",
      "[2019-08-10 05:27:00,977] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/DoOnce/Read_307)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/MergeCombinesGlobally/InjectDefault_308))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_2/quantiles]/ExtractOutputs/FlatMap(extract_outputs)_310))+(((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[bucketize_2/quantiles/Placeholder]_311)+(AnalyzeDataset/CreateSavedModel/Flatten/Transcode/0))+(AnalyzeDataset/CreateSavedModel/Flatten/Write/0))\n",
      "[2019-08-10 05:27:01,004] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/DoOnce/Read_405)+(ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/InitializeWrite_406))+(ref_PCollection_PCollection_250/Write))+(ref_PCollection_PCollection_251/Write)\n",
      "[2019-08-10 05:27:01,026] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/DoOnce/Read_243)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/MergeCombinesGlobally/InjectDefault_244)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize/quantiles]/ExtractOutputs/FlatMap(extract_outputs)_246)))+((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[bucketize/quantiles/Placeholder]_247)+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/10)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/10)))\n",
      "[2019-08-10 05:27:01,059] {fn_api_runner.py:577} INFO - Running ((AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Read)+((AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/CombinePerKey/Merge)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/CombinePerKey/ExtractOutputs)))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/UnKey_323)+(ref_PCollection_PCollection_201/Write))\n",
      "[2019-08-10 05:27:01,163] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/DoOnce/Read_325)+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_3/quantiles]/InitialCombineGlobally/InjectDefault_326)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/KeyWithVoid_329)+(AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/CombinePerKey/Precombine)))+(AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Write))\n",
      "[2019-08-10 05:27:01,229] {fn_api_runner.py:577} INFO - Running ((AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Read)+((AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/CombinePerKey/Merge)+(AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs)))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/UnKey_337)+(ref_PCollection_PCollection_209/Write))\n",
      "[2019-08-10 05:27:01,333] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/DoOnce/Read_339)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/MergeCombinesGlobally/InjectDefault_340))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_3/quantiles]/ExtractOutputs/FlatMap(extract_outputs)_342))+(((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[bucketize_3/quantiles/Placeholder]_343)+(AnalyzeDataset/CreateSavedModel/Flatten/Transcode/1))+(AnalyzeDataset/CreateSavedModel/Flatten/Write/1))\n",
      "[2019-08-10 05:27:01,363] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/DoOnce/Read_143)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/InitializeWrite_144)+(ref_PCollection_PCollection_87/Write)))+(ref_PCollection_PCollection_86/Write)\n",
      "[2019-08-10 05:27:01,386] {fn_api_runner.py:577} INFO - Running (((((AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Group/Read)+(AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Merge))+(AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/ExtractOutputs))+(ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary/vocabulary]/FilterProblematicStrings_112))+(AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/CountPerString/Precombine))+(AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/CountPerString/Group/Write)\n",
      "[2019-08-10 05:27:01,413] {fn_api_runner.py:577} INFO - Running ((((AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/CountPerString/Group/Read)+(AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/CountPerString/Merge))+((AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/CountPerString/ExtractOutputs)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary/vocabulary]/SwapStringsAndCounts_121)))+(ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/ParDo(_TopPerBundle)_125))+((AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Transcode/0)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Write/0))\n",
      "[2019-08-10 05:27:01,439] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Create/Read_127)+((AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Transcode/1)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Write/1))\n",
      "[2019-08-10 05:27:01,458] {fn_api_runner.py:577} INFO - Running (AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Read)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/GroupByKey/Write)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:27:01,476] {fn_api_runner.py:577} INFO - Running (AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/GroupByKey/Read)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/ParDo(_MergeTopPerBundle)_133)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary/vocabulary]/ApplyFrequencyThresholdAndTopK/FlattenList_134)+(ref_PCollection_PCollection_83/Write)))\n",
      "[2019-08-10 05:27:01,501] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/Prepare/Read_137)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/OrderElements_138))+((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/Map(<lambda at iobase.py:989>)_145)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/WindowInto(WindowIntoFn)_146)+(AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/GroupByKey/Write)))\n",
      "[2019-08-10 05:27:01,534] {fn_api_runner.py:577} INFO - Running ((AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/WriteBundles_151))+(ref_PCollection_PCollection_93/Write)\n",
      "[2019-08-10 05:27:01,559] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_86/Read)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/PreFinalize_152)+(ref_PCollection_PCollection_94/Write))\n",
      "[2019-08-10 05:27:01,582] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_86/Read)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WriteToFile/Write/WriteImpl/FinalizeWrite_153)+(ref_PCollection_PCollection_95/Write))\n",
      "[2019-08-10 05:27:01,600] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "[2019-08-10 05:27:01,707] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n",
      "[2019-08-10 05:27:01,731] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/CreatePath/Read_155)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary/vocabulary]/WaitForVocabularyFile_156))+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[compute_and_apply_vocabulary/vocabulary/Placeholder]_157))+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/8)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/8))\n",
      "[2019-08-10 05:27:01,766] {fn_api_runner.py:577} INFO - Running ((((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/CombinePerKey/ExtractOutputs))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_2/mean_and_var]/InitialCombineGlobally/UnKey_84)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/KeyWithVoid_87)))+((AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Precombine)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Write))\n",
      "[2019-08-10 05:27:01,805] {fn_api_runner.py:577} INFO - Running (AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Read)+((((AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Merge)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs))+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/MergeCombinesGlobally/UnKey_95)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_2/mean_and_var]/ExtractOutputs/FlatMap(extract_outputs)_97)+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score_2/mean_and_var/Placeholder]_98)))+((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score_2/mean_and_var/Placeholder_1]_99)+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/7)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/7)))))+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/6)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/6)))\n",
      "[2019-08-10 05:27:01,849] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/DoOnce/Read_201)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/InitializeWrite_202))+(ref_PCollection_PCollection_122/Write))+(ref_PCollection_PCollection_123/Write)\n",
      "[2019-08-10 05:27:01,876] {fn_api_runner.py:577} INFO - Running ((AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Group/Read)+((AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/Merge)+(AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/CombinePerKey(CountCombineFn)/ExtractOutputs)))+((ref_AppliedPTransform_AnalyzeDataset/VocabularyAccumulate[compute_and_apply_vocabulary_1/vocabulary]/FilterProblematicStrings_170)+((AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/Precombine)+(AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/Group/Write)))\n",
      "[2019-08-10 05:27:01,909] {fn_api_runner.py:577} INFO - Running ((((AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/Group/Read)+((AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/Merge)+(AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/CountPerString/ExtractOutputs)))+(ref_AppliedPTransform_AnalyzeDataset/VocabularyMerge[compute_and_apply_vocabulary_1/vocabulary]/SwapStringsAndCounts_179))+((ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/ParDo(_TopPerBundle)_183)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Transcode/1)))+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Write/1)\n",
      "[2019-08-10 05:27:01,943] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Create/Read_185)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Transcode/0))+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Write/0)\n",
      "[2019-08-10 05:27:01,967] {fn_api_runner.py:577} INFO - Running (AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/Flatten/Read)+(AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/GroupByKey/Write)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:27:01,992] {fn_api_runner.py:577} INFO - Running (AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/GroupByKey/Read)+(((ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/Top(1000)/ParDo(_MergeTopPerBundle)_191)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyOrderAndFilter[compute_and_apply_vocabulary_1/vocabulary]/ApplyFrequencyThresholdAndTopK/FlattenList_192))+(ref_PCollection_PCollection_119/Write))\n",
      "[2019-08-10 05:27:02,020] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/Prepare/Read_195)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/OrderElements_196))+(((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/Map(<lambda at iobase.py:989>)_203)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/WindowInto(WindowIntoFn)_204))+(AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/GroupByKey/Write))\n",
      "[2019-08-10 05:27:02,056] {fn_api_runner.py:577} INFO - Running ((AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/WriteBundles_209))+(ref_PCollection_PCollection_129/Write)\n",
      "[2019-08-10 05:27:02,079] {fn_api_runner.py:577} INFO - Running ((ref_PCollection_PCollection_122/Read)+(ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/PreFinalize_210))+(ref_PCollection_PCollection_130/Write)\n",
      "[2019-08-10 05:27:02,102] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_122/Read)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WriteToFile/Write/WriteImpl/FinalizeWrite_211)+(ref_PCollection_PCollection_131/Write))\n",
      "[2019-08-10 05:27:02,120] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "[2019-08-10 05:27:02,228] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n",
      "[2019-08-10 05:27:02,250] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/CreatePath/Read_213)+((ref_AppliedPTransform_AnalyzeDataset/VocabularyWrite[compute_and_apply_vocabulary_1/vocabulary]/WaitForVocabularyFile_214)+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[compute_and_apply_vocabulary_1/vocabulary/Placeholder]_215)))+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/9)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/9))\n",
      "[2019-08-10 05:27:02,282] {fn_api_runner.py:577} INFO - Running ((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Read)+((((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/CombinePerKey/Merge)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/CombinePerKey/ExtractOutputs))+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score_1/mean_and_var]/InitialCombineGlobally/UnKey_57))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/KeyWithVoid_60)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Precombine))))+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Write)\n",
      "[2019-08-10 05:27:02,312] {fn_api_runner.py:577} INFO - Running ((AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Read)+(((((AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Merge)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs))+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/MergeCombinesGlobally/UnKey_68)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score_1/mean_and_var]/ExtractOutputs/FlatMap(extract_outputs)_70)+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score_1/mean_and_var/Placeholder]_71)))+(AnalyzeDataset/CreateSavedModel/Flatten/Transcode/4)))+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score_1/mean_and_var/Placeholder_1]_72))+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/5)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/5))))+(AnalyzeDataset/CreateSavedModel/Flatten/Write/4)\n",
      "[2019-08-10 05:27:02,349] {fn_api_runner.py:577} INFO - Running (((AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/CombinePerKey/ExtractOutputs))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[scale_to_z_score/mean_and_var]/InitialCombineGlobally/UnKey_30)+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/KeyWithVoid_33)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Precombine))+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Write)))\n",
      "[2019-08-10 05:27:02,379] {fn_api_runner.py:577} INFO - Running ((((AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs))+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/MergeCombinesGlobally/UnKey_41)+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[scale_to_z_score/mean_and_var]/ExtractOutputs/FlatMap(extract_outputs)_43)+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score/mean_and_var/Placeholder_1]_45)))+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/3)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/3))))+((ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[scale_to_z_score/mean_and_var/Placeholder]_44)+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/2)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/2)))\n",
      "[2019-08-10 05:27:02,417] {fn_api_runner.py:577} INFO - Running (((AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/CombinePerKey/Group/Read)+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/CombinePerKey/Merge))+(AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/CombinePerKey/ExtractOutputs))+((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/UnKey_259)+(ref_PCollection_PCollection_161/Write))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:27:02,567] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/DoOnce/Read_261)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineAccumulate[bucketize_1/quantiles]/InitialCombineGlobally/InjectDefault_262))+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/KeyWithVoid_265)+(AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/CombinePerKey/Precombine))+(AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Write))\n",
      "[2019-08-10 05:27:02,645] {fn_api_runner.py:577} INFO - Running (AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/CombinePerKey/Group/Read)+((AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/CombinePerKey/Merge)+(((AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/CombinePerKey/ExtractOutputs)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/UnKey_273))+(ref_PCollection_PCollection_169/Write)))\n",
      "[2019-08-10 05:27:02,761] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/DoOnce/Read_275)+(ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/MergeCombinesGlobally/InjectDefault_276))+(((ref_AppliedPTransform_AnalyzeDataset/CacheableCombineMerge[bucketize_1/quantiles]/ExtractOutputs/FlatMap(extract_outputs)_278)+(ref_AppliedPTransform_AnalyzeDataset/CreateTensorBinding[bucketize_1/quantiles/Placeholder]_279))+((AnalyzeDataset/CreateSavedModel/Flatten/Transcode/11)+(AnalyzeDataset/CreateSavedModel/Flatten/Write/11)))\n",
      "[2019-08-10 05:27:02,790] {fn_api_runner.py:577} INFO - Running (AnalyzeDataset/CreateSavedModel/Flatten/Read)+(ref_PCollection_PCollection_216/Write)\n",
      "[2019-08-10 05:27:02,807] {fn_api_runner.py:577} INFO - Running (((((((ref_AppliedPTransform_AnalyzeDataset/CreateSavedModel/CreateSavedModel/Read_346)+(ref_AppliedPTransform_AnalyzeDataset/CreateSavedModel/BindTensors_348))+(ref_AppliedPTransform_AnalyzeDataset/ComputeDeferredMetadata_349))+(ref_AppliedPTransform_AnalyzeDataset/MakeCheapBarrier_350))+(ref_PCollection_PCollection_217/Write))+(ref_AppliedPTransform_WriteTransformFn/WriteMetadata/WriteMetadata_360))+(ref_PCollection_PCollection_219/Write))+(ref_PCollection_PCollection_224/Write)\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:27:02,922] {saver.py:1483} INFO - Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "[2019-08-10 05:27:02,944] {builder_impl.py:654} INFO - Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: /root/taxi/data/simple/transform/transform_output/.temp_path/tftransform_tmp/d53fae6504a44e438669d2225ea2e16e/assets\n",
      "[2019-08-10 05:27:02,952] {builder_impl.py:763} INFO - Assets written to: /root/taxi/data/simple/transform/transform_output/.temp_path/tftransform_tmp/d53fae6504a44e438669d2225ea2e16e/assets\n",
      "INFO:tensorflow:SavedModel written to: /root/taxi/data/simple/transform/transform_output/.temp_path/tftransform_tmp/d53fae6504a44e438669d2225ea2e16e/saved_model.pb\n",
      "[2019-08-10 05:27:02,993] {builder_impl.py:414} INFO - SavedModel written to: /root/taxi/data/simple/transform/transform_output/.temp_path/tftransform_tmp/d53fae6504a44e438669d2225ea2e16e/saved_model.pb\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "[2019-08-10 05:27:03,272] {ops.py:6153} WARNING - Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "[2019-08-10 05:27:03,279] {ops.py:6153} WARNING - Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:27:03,288] {saver.py:1483} INFO - Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:27:03,397] {fn_api_runner.py:577} INFO - Running (((((ref_AppliedPTransform_ReadTransformDataset[0]/Read/Read_365)+(ref_AppliedPTransform_ReadTransformDataset[0]/AddKey_366))+(((ref_AppliedPTransform_ReadTransformDataset[0]/ParseExamples_367)+(ref_AppliedPTransform_DecodeTransformDataset[0]/ApplyDecodeFn_369))+(ref_AppliedPTransform_TransformDataset[0]/Batch/BatchElements/ParDo(_GlobalWindowsBatchingDoFn)_373)))+(((ref_AppliedPTransform_TransformDataset[0]/Transform_374)+(((ref_AppliedPTransform_TransformDataset[0]/ConvertAndUnbatch_375)+(ref_AppliedPTransform_TransformDataset[0]/MakeCheapBarrier_376))+(ref_AppliedPTransform_EncodeTransformedDataset[0]_380)))+(ref_AppliedPTransform_Materialize[0]/DropNoneKeys_400)))+(ref_PCollection_PCollection_234/Write))+((ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/WriteBundles_407)+((ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/Pair_408)+((ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/WindowInto(WindowIntoFn)_409)+(Materialize[0]/Write/Write/WriteImpl/GroupByKey/Write))))\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "[2019-08-10 05:27:03,560] {ops.py:6153} WARNING - Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "[2019-08-10 05:27:03,567] {ops.py:6153} WARNING - Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:27:03,576] {saver.py:1483} INFO - Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:27:07,031] {fn_api_runner.py:577} INFO - Running ((Materialize[0]/Write/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/Extract_414))+(ref_PCollection_PCollection_258/Write)\n",
      "[2019-08-10 05:27:07,055] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_217/Read)+((ref_AppliedPTransform_WriteTransformFn/WriteTransformFn_361)+(ref_AppliedPTransform_WriteTransformFn/WaitOnWriteMetadataDone_362))\n",
      "[2019-08-10 05:27:07,083] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_250/Read)+((ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/PreFinalize_415)+(ref_PCollection_PCollection_259/Write))\n",
      "[2019-08-10 05:27:07,108] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_250/Read)+(ref_AppliedPTransform_Materialize[0]/Write/Write/WriteImpl/FinalizeWrite_416)\n",
      "[2019-08-10 05:27:07,127] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "[2019-08-10 05:27:07,235] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:27:07,261] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/DoOnce/Read_423)+((ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/InitializeWrite_424)+(ref_PCollection_PCollection_263/Write)))+(ref_PCollection_PCollection_262/Write)\n",
      "[2019-08-10 05:27:07,289] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_ReadTransformDataset[1]/Read/Read_383)+((ref_AppliedPTransform_ReadTransformDataset[1]/AddKey_384)+(ref_AppliedPTransform_ReadTransformDataset[1]/ParseExamples_385)))+((ref_AppliedPTransform_DecodeTransformDataset[1]/ApplyDecodeFn_387)+(((ref_AppliedPTransform_TransformDataset[1]/Batch/BatchElements/ParDo(_GlobalWindowsBatchingDoFn)_391)+(ref_AppliedPTransform_TransformDataset[1]/Transform_392))+(((((ref_AppliedPTransform_TransformDataset[1]/ConvertAndUnbatch_393)+(ref_AppliedPTransform_TransformDataset[1]/MakeCheapBarrier_394))+(ref_AppliedPTransform_EncodeTransformedDataset[1]_398))+(ref_PCollection_PCollection_245/Write))+((((ref_AppliedPTransform_Materialize[1]/DropNoneKeys_418)+(ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/WriteBundles_425))+((ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/Pair_426)+(ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/WindowInto(WindowIntoFn)_427)))+(Materialize[1]/Write/Write/WriteImpl/GroupByKey/Write)))))\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "[2019-08-10 05:27:07,424] {ops.py:6153} WARNING - Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "[2019-08-10 05:27:07,430] {ops.py:6153} WARNING - Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:27:07,441] {saver.py:1483} INFO - Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:27:09,324] {fn_api_runner.py:577} INFO - Running ((Materialize[1]/Write/Write/WriteImpl/GroupByKey/Read)+(ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/Extract_432))+(ref_PCollection_PCollection_270/Write)\n",
      "[2019-08-10 05:27:09,347] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_262/Read)+((ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/PreFinalize_433)+(ref_PCollection_PCollection_271/Write))\n",
      "[2019-08-10 05:27:09,372] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_262/Read)+(ref_AppliedPTransform_Materialize[1]/Write/Write/WriteImpl/FinalizeWrite_434)\n",
      "[2019-08-10 05:27:09,390] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "[2019-08-10 05:27:09,497] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n",
      "[2019-08-10 05:27:09,520] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_TransformDataset[0]/PrepareToClearSharedKeepAlives/Read_378)+(ref_AppliedPTransform_TransformDataset[0]/WaitAndClearSharedKeepAlives_379)\n",
      "[2019-08-10 05:27:09,546] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_TransformDataset[1]/PrepareToClearSharedKeepAlives/Read_396)+(ref_AppliedPTransform_TransformDataset[1]/WaitAndClearSharedKeepAlives_397)\n",
      "[2019-08-10 05:27:09,572] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_AnalyzeDataset/PrepareToClearSharedKeepAlives/Read_352)+(ref_AppliedPTransform_AnalyzeDataset/WaitAndClearSharedKeepAlives_353)\n",
      "[2019-08-10 05:27:09,596] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_WriteMetadata/Create/Read_356)+(ref_AppliedPTransform_WriteMetadata/WriteMetadata_357)\n",
      "INFO:tensorflow:Cleaning up temp path /root/taxi/data/simple/transform/transform_output/.temp_path on executor success\n",
      "[2019-08-10 05:27:09,637] {executor.py:248} INFO - Cleaning up temp path /root/taxi/data/simple/transform/transform_output/.temp_path on executor success\n",
      "INFO:tensorflow:Starting Executor execution.\n",
      "[2019-08-10 05:27:09,650] {base_executor.py:72} INFO - Starting Executor execution.\n",
      "INFO:tensorflow:Inputs for Executor is: {\"transformed_examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/transform/transformed_examples/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/transform/transformed_examples/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"schema\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"SchemaPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/schema_gen/\"}, \"artifact_type\": {\"name\": \"SchemaPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"transform_output\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"TransformPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple/transform/transform_output/\"}, \"artifact_type\": {\"name\": \"TransformPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "[2019-08-10 05:27:09,659] {base_executor.py:74} INFO - Inputs for Executor is: {\"transformed_examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/transform/transformed_examples/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/transform/transformed_examples/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"schema\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"SchemaPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/schema_gen/\"}, \"artifact_type\": {\"name\": \"SchemaPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"transform_output\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"TransformPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple/transform/transform_output/\"}, \"artifact_type\": {\"name\": \"TransformPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "INFO:tensorflow:Outputs for Executor is: {\"output\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ModelExportPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple/trainer/current/\"}, \"artifact_type\": {\"name\": \"ModelExportPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "[2019-08-10 05:27:09,667] {base_executor.py:76} INFO - Outputs for Executor is: {\"output\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ModelExportPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple/trainer/current/\"}, \"artifact_type\": {\"name\": \"ModelExportPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "INFO:tensorflow:Execution properties for Executor is: {\"module_file\": \"/root/taxi/taxi_utils.py\", \"custom_config\": null, \"eval_args\": \"{\\n  \\\"numSteps\\\": 5000\\n}\", \"train_args\": \"{\\n  \\\"numSteps\\\": 10000\\n}\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:27:09,675] {base_executor.py:78} INFO - Execution properties for Executor is: {\"module_file\": \"/root/taxi/taxi_utils.py\", \"custom_config\": null, \"eval_args\": \"{\\n  \\\"numSteps\\\": 5000\\n}\", \"train_args\": \"{\\n  \\\"numSteps\\\": 10000\\n}\"}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': 999, '_log_step_count_steps': 100, '_service': None, '_eval_distribute': None, '_save_checkpoints_secs': None, '_task_id': 0, '_tf_random_seed': None, '_evaluation_master': '', '_device_fn': None, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3cd54b6e10>, '_protocol': None, '_model_dir': '/root/taxi/data/simple/trainer/current/serving_model_dir', '_experimental_distribute': None, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_task_type': 'worker', '_is_chief': True, '_train_distribute': None, '_master': '', '_keep_checkpoint_max': 1}\n",
      "[2019-08-10 05:27:09,693] {estimator.py:201} INFO - Using config: {'_save_checkpoints_steps': 999, '_log_step_count_steps': 100, '_service': None, '_eval_distribute': None, '_save_checkpoints_secs': None, '_task_id': 0, '_tf_random_seed': None, '_evaluation_master': '', '_device_fn': None, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3cd54b6e10>, '_protocol': None, '_model_dir': '/root/taxi/data/simple/trainer/current/serving_model_dir', '_experimental_distribute': None, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_task_type': 'worker', '_is_chief': True, '_train_distribute': None, '_master': '', '_keep_checkpoint_max': 1}\n",
      "INFO:tensorflow:Training model.\n",
      "[2019-08-10 05:27:09,701] {executor.py:141} INFO - Training model.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "[2019-08-10 05:27:09,708] {estimator_training.py:185} INFO - Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "[2019-08-10 05:27:09,717] {training.py:610} INFO - Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 999 or save_checkpoints_secs None.\n",
      "[2019-08-10 05:27:09,724] {training.py:698} INFO - Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 999 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[2019-08-10 05:27:09,738] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /root/taxi/taxi_utils.py:290: read_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "[2019-08-10 05:27:09,765] {deprecation.py:323} WARNING - From /root/taxi/taxi_utils.py:290: read_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:833: read_keyed_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "[2019-08-10 05:27:09,777] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:833: read_keyed_batch_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:542: read_keyed_batch_examples (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "[2019-08-10 05:27:09,789] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:542: read_keyed_batch_examples (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:423: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "[2019-08-10 05:27:09,807] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:423: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "[2019-08-10 05:27:09,838] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "[2019-08-10 05:27:09,857] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:27:09,875] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "[2019-08-10 05:27:09,889] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[2019-08-10 05:27:09,905] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /root/taxi/taxi_utils.py:88: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "[2019-08-10 05:27:09,921] {deprecation.py:323} WARNING - From /root/taxi/taxi_utils.py:88: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:449: shuffle_batch_join (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.interleave(...).shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "[2019-08-10 05:27:09,938] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:449: shuffle_batch_join (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.interleave(...).shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:550: queue_parsed_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "[2019-08-10 05:27:09,986] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/graph_io.py:550: queue_parsed_features (from tensorflow.contrib.learn.python.learn.learn_io.graph_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.data.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "[2019-08-10 05:27:10,011] {estimator.py:1111} INFO - Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "[2019-08-10 05:27:11,583] {estimator.py:1113} INFO - Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "[2019-08-10 05:27:11,590] {basic_session_run_hooks.py:527} INFO - Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "[2019-08-10 05:27:12,164] {monitored_session.py:222} INFO - Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "[2019-08-10 05:27:12,313] {session_manager.py:491} INFO - Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[2019-08-10 05:27:12,346] {session_manager.py:493} INFO - Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "[2019-08-10 05:27:12,397] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1403, in _train_with_estimator_spec\n",
      "    log_step_count_steps=log_step_count_steps) as mon_sess:\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 508, in MonitoredTrainingSession\n",
      "    stop_grace_period_secs=stop_grace_period_secs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 934, in __init__\n",
      "    stop_grace_period_secs=stop_grace_period_secs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 648, in __init__\n",
      "    self._sess = _RecoverableSession(self._coordinated_creator)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1122, in __init__\n",
      "    _WrappedSession.__init__(self, self._create_session())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1127, in _create_session\n",
      "    return self._sess_creator.create_session()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 812, in create_session\n",
      "    hook.after_create_session(self.tf_sess, self.coord)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 568, in after_create_session\n",
      "    self._save(session, global_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m0\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 27.703003, step = 1\n",
      "[2019-08-10 05:27:14,201] {basic_session_run_hooks.py:249} INFO - loss = 27.703003, step = 1\n",
      "INFO:tensorflow:global_step/sec: 211.569\n",
      "[2019-08-10 05:27:14,673] {basic_session_run_hooks.py:680} INFO - global_step/sec: 211.569\n",
      "INFO:tensorflow:loss = 23.876247, step = 101 (0.481 sec)\n",
      "[2019-08-10 05:27:14,681] {basic_session_run_hooks.py:247} INFO - loss = 23.876247, step = 101 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.091\n",
      "[2019-08-10 05:27:14,867] {basic_session_run_hooks.py:680} INFO - global_step/sec: 515.091\n",
      "INFO:tensorflow:loss = 18.412708, step = 201 (0.195 sec)\n",
      "[2019-08-10 05:27:14,876] {basic_session_run_hooks.py:247} INFO - loss = 18.412708, step = 201 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.015\n",
      "[2019-08-10 05:27:15,085] {basic_session_run_hooks.py:680} INFO - global_step/sec: 458.015\n",
      "INFO:tensorflow:loss = 19.566767, step = 301 (0.219 sec)\n",
      "[2019-08-10 05:27:15,095] {basic_session_run_hooks.py:247} INFO - loss = 19.566767, step = 301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.623\n",
      "[2019-08-10 05:27:15,337] {basic_session_run_hooks.py:680} INFO - global_step/sec: 397.623\n",
      "INFO:tensorflow:loss = 22.55878, step = 401 (0.251 sec)\n",
      "[2019-08-10 05:27:15,346] {basic_session_run_hooks.py:247} INFO - loss = 22.55878, step = 401 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.776\n",
      "[2019-08-10 05:27:15,527] {basic_session_run_hooks.py:680} INFO - global_step/sec: 526.776\n",
      "INFO:tensorflow:loss = 20.89058, step = 501 (0.190 sec)\n",
      "[2019-08-10 05:27:15,536] {basic_session_run_hooks.py:247} INFO - loss = 20.89058, step = 501 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.375\n",
      "[2019-08-10 05:27:15,741] {basic_session_run_hooks.py:680} INFO - global_step/sec: 467.375\n",
      "INFO:tensorflow:loss = 18.717243, step = 601 (0.216 sec)\n",
      "[2019-08-10 05:27:15,752] {basic_session_run_hooks.py:247} INFO - loss = 18.717243, step = 601 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.855\n",
      "[2019-08-10 05:27:15,957] {basic_session_run_hooks.py:680} INFO - global_step/sec: 461.855\n",
      "INFO:tensorflow:loss = 24.35092, step = 701 (0.213 sec)\n",
      "[2019-08-10 05:27:15,965] {basic_session_run_hooks.py:247} INFO - loss = 24.35092, step = 701 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.561\n",
      "[2019-08-10 05:27:16,157] {basic_session_run_hooks.py:680} INFO - global_step/sec: 500.561\n",
      "INFO:tensorflow:loss = 22.152079, step = 801 (0.204 sec)\n",
      "[2019-08-10 05:27:16,169] {basic_session_run_hooks.py:247} INFO - loss = 22.152079, step = 801 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.834\n",
      "[2019-08-10 05:27:16,355] {basic_session_run_hooks.py:680} INFO - global_step/sec: 503.834\n",
      "INFO:tensorflow:loss = 16.390858, step = 901 (0.196 sec)\n",
      "[2019-08-10 05:27:16,364] {basic_session_run_hooks.py:247} INFO - loss = 16.390858, step = 901 (0.196 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 999 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m999\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "[2019-08-10 05:27:16,660] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "[2019-08-10 05:27:16,883] {estimator.py:1111} INFO - Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "[2019-08-10 05:27:17,892] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "[2019-08-10 05:27:18,097] {metrics_impl.py:783} WARNING - Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "[2019-08-10 05:27:18,124] {metrics_impl.py:783} WARNING - Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "[2019-08-10 05:27:18,151] {estimator.py:1113} INFO - Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-08-10T05:27:18Z\n",
      "[2019-08-10 05:27:18,178] {evaluation.py:257} INFO - Starting evaluation at 2019-08-10T05:27:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "[2019-08-10 05:27:18,565] {monitored_session.py:222} INFO - Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "[2019-08-10 05:27:18,572] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-999\n",
      "[2019-08-10 05:27:18,599] {saver.py:1270} INFO - Restoring parameters from /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-999\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "[2019-08-10 05:27:18,708] {session_manager.py:491} INFO - Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[2019-08-10 05:27:18,750] {session_manager.py:493} INFO - Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [500/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m500\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1000/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m1000\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1500/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m1500\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2000/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m2000\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2500/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m2500\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3000/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m3000\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3500/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m3500\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4000/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m4000\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4500/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m4500\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5000/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m5000\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-08-10-05:27:29\n",
      "[2019-08-10 05:27:29,747] {evaluation.py:277} INFO - Finished evaluation at 2019-08-10-05:27:29\n",
      "INFO:tensorflow:Saving dict for global step 999: accuracy = 0.76969, accuracy_baseline = 0.76989, auc = 0.9050932, auc_precision_recall = 0.6370034, average_loss = 0.45125017, global_step = 999, label/mean = 0.23011, loss = 18.050007, precision = 0.0, prediction/mean = 0.23003985, recall = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1544, in _evaluate_run\n",
      "    current_global_step=current_global_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1979, in _write_dict_to_summary\n",
      "    _dict_to_str(dictionary))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving dict for global step %d: %s'\n",
      "Arguments: ('\\x1b[1m999\\x1b[0m', '\\x1b[1maccuracy = 0.76969, accuracy_baseline = 0.76989, auc = 0.9050932, auc_precision_recall = 0.6370034, average_loss = 0.45125017, global_step = 999, label/mean = 0.23011, loss = 18.050007, precision = 0.0, prediction/mean = 0.23003985, recall = 0.0\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 999: /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1550, in _evaluate_run\n",
      "    current_global_step=current_global_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 2039, in _write_checkpoint_path_to_summary\n",
      "    checkpoint_path_tag, current_global_step, checkpoint_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: \"Saving '%s' summary for global step %d: %s\"\n",
      "Arguments: ('\\x1b[1mcheckpoint_path\\x1b[0m', '\\x1b[1m999\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-999\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 7.25859\n",
      "[2019-08-10 05:27:30,132] {basic_session_run_hooks.py:680} INFO - global_step/sec: 7.25859\n",
      "INFO:tensorflow:loss = 19.105305, step = 1001 (13.778 sec)\n",
      "[2019-08-10 05:27:30,142] {basic_session_run_hooks.py:247} INFO - loss = 19.105305, step = 1001 (13.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.567\n",
      "[2019-08-10 05:27:30,379] {basic_session_run_hooks.py:680} INFO - global_step/sec: 405.567\n",
      "INFO:tensorflow:loss = 21.340107, step = 1101 (0.246 sec)\n",
      "[2019-08-10 05:27:30,388] {basic_session_run_hooks.py:247} INFO - loss = 21.340107, step = 1101 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.051\n",
      "[2019-08-10 05:27:30,603] {basic_session_run_hooks.py:680} INFO - global_step/sec: 446.051\n",
      "INFO:tensorflow:loss = 13.8021, step = 1201 (0.225 sec)\n",
      "[2019-08-10 05:27:30,613] {basic_session_run_hooks.py:247} INFO - loss = 13.8021, step = 1201 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.173\n",
      "[2019-08-10 05:27:30,844] {basic_session_run_hooks.py:680} INFO - global_step/sec: 414.173\n",
      "INFO:tensorflow:loss = 17.084084, step = 1301 (0.240 sec)\n",
      "[2019-08-10 05:27:30,853] {basic_session_run_hooks.py:247} INFO - loss = 17.084084, step = 1301 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.563\n",
      "[2019-08-10 05:27:31,083] {basic_session_run_hooks.py:680} INFO - global_step/sec: 419.563\n",
      "INFO:tensorflow:loss = 17.189983, step = 1401 (0.239 sec)\n",
      "[2019-08-10 05:27:31,092] {basic_session_run_hooks.py:247} INFO - loss = 17.189983, step = 1401 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.097\n",
      "[2019-08-10 05:27:31,278] {basic_session_run_hooks.py:680} INFO - global_step/sec: 511.097\n",
      "INFO:tensorflow:loss = 18.100986, step = 1501 (0.193 sec)\n",
      "[2019-08-10 05:27:31,285] {basic_session_run_hooks.py:247} INFO - loss = 18.100986, step = 1501 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.389\n",
      "[2019-08-10 05:27:31,534] {basic_session_run_hooks.py:680} INFO - global_step/sec: 390.389\n",
      "INFO:tensorflow:loss = 15.342095, step = 1601 (0.260 sec)\n",
      "[2019-08-10 05:27:31,545] {basic_session_run_hooks.py:247} INFO - loss = 15.342095, step = 1601 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.295\n",
      "[2019-08-10 05:27:31,772] {basic_session_run_hooks.py:680} INFO - global_step/sec: 421.295\n",
      "INFO:tensorflow:loss = 20.0341, step = 1701 (0.235 sec)\n",
      "[2019-08-10 05:27:31,780] {basic_session_run_hooks.py:247} INFO - loss = 20.0341, step = 1701 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.737\n",
      "[2019-08-10 05:27:31,963] {basic_session_run_hooks.py:680} INFO - global_step/sec: 523.737\n",
      "INFO:tensorflow:loss = 22.045948, step = 1801 (0.191 sec)\n",
      "[2019-08-10 05:27:31,971] {basic_session_run_hooks.py:247} INFO - loss = 22.045948, step = 1801 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.941\n",
      "[2019-08-10 05:27:32,194] {basic_session_run_hooks.py:680} INFO - global_step/sec: 431.941\n",
      "INFO:tensorflow:loss = 15.952551, step = 1901 (0.232 sec)\n",
      "[2019-08-10 05:27:32,203] {basic_session_run_hooks.py:247} INFO - loss = 15.952551, step = 1901 (0.232 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1998 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m1998\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "[2019-08-10 05:27:32,594] {training.py:525} INFO - Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 240.332\n",
      "[2019-08-10 05:27:32,610] {basic_session_run_hooks.py:680} INFO - global_step/sec: 240.332\n",
      "INFO:tensorflow:loss = 16.209446, step = 2001 (0.418 sec)\n",
      "[2019-08-10 05:27:32,621] {basic_session_run_hooks.py:247} INFO - loss = 16.209446, step = 2001 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.234\n",
      "[2019-08-10 05:27:32,820] {basic_session_run_hooks.py:680} INFO - global_step/sec: 477.234\n",
      "INFO:tensorflow:loss = 16.505407, step = 2101 (0.207 sec)\n",
      "[2019-08-10 05:27:32,828] {basic_session_run_hooks.py:247} INFO - loss = 16.505407, step = 2101 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.176\n",
      "[2019-08-10 05:27:33,044] {basic_session_run_hooks.py:680} INFO - global_step/sec: 447.176\n",
      "INFO:tensorflow:loss = 13.327009, step = 2201 (0.222 sec)\n",
      "[2019-08-10 05:27:33,050] {basic_session_run_hooks.py:247} INFO - loss = 13.327009, step = 2201 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.089\n",
      "[2019-08-10 05:27:33,303] {basic_session_run_hooks.py:680} INFO - global_step/sec: 386.089\n",
      "INFO:tensorflow:loss = 18.96377, step = 2301 (0.262 sec)\n",
      "[2019-08-10 05:27:33,312] {basic_session_run_hooks.py:247} INFO - loss = 18.96377, step = 2301 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.832\n",
      "[2019-08-10 05:27:33,537] {basic_session_run_hooks.py:680} INFO - global_step/sec: 426.832\n",
      "INFO:tensorflow:loss = 19.015253, step = 2401 (0.233 sec)\n",
      "[2019-08-10 05:27:33,544] {basic_session_run_hooks.py:247} INFO - loss = 19.015253, step = 2401 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.839\n",
      "[2019-08-10 05:27:33,786] {basic_session_run_hooks.py:680} INFO - global_step/sec: 400.839\n",
      "INFO:tensorflow:loss = 14.575837, step = 2501 (0.250 sec)\n",
      "[2019-08-10 05:27:33,794] {basic_session_run_hooks.py:247} INFO - loss = 14.575837, step = 2501 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.482\n",
      "[2019-08-10 05:27:33,985] {basic_session_run_hooks.py:680} INFO - global_step/sec: 502.482\n",
      "INFO:tensorflow:loss = 12.7233715, step = 2601 (0.201 sec)\n",
      "[2019-08-10 05:27:33,995] {basic_session_run_hooks.py:247} INFO - loss = 12.7233715, step = 2601 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.746\n",
      "[2019-08-10 05:27:34,189] {basic_session_run_hooks.py:680} INFO - global_step/sec: 490.746\n",
      "INFO:tensorflow:loss = 14.646028, step = 2701 (0.201 sec)\n",
      "[2019-08-10 05:27:34,196] {basic_session_run_hooks.py:247} INFO - loss = 14.646028, step = 2701 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.138\n",
      "[2019-08-10 05:27:34,385] {basic_session_run_hooks.py:680} INFO - global_step/sec: 510.138\n",
      "INFO:tensorflow:loss = 19.926428, step = 2801 (0.199 sec)\n",
      "[2019-08-10 05:27:34,395] {basic_session_run_hooks.py:247} INFO - loss = 19.926428, step = 2801 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.867\n",
      "[2019-08-10 05:27:34,597] {basic_session_run_hooks.py:680} INFO - global_step/sec: 472.867\n",
      "INFO:tensorflow:loss = 13.411549, step = 2901 (0.211 sec)\n",
      "[2019-08-10 05:27:34,606] {basic_session_run_hooks.py:247} INFO - loss = 13.411549, step = 2901 (0.211 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2997 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m2997\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "[2019-08-10 05:27:35,054] {training.py:525} INFO - Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 209.697\n",
      "[2019-08-10 05:27:35,074] {basic_session_run_hooks.py:680} INFO - global_step/sec: 209.697\n",
      "INFO:tensorflow:loss = 12.996763, step = 3001 (0.478 sec)\n",
      "[2019-08-10 05:27:35,084] {basic_session_run_hooks.py:247} INFO - loss = 12.996763, step = 3001 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.362\n",
      "[2019-08-10 05:27:35,311] {basic_session_run_hooks.py:680} INFO - global_step/sec: 420.362\n",
      "INFO:tensorflow:loss = 21.710125, step = 3101 (0.237 sec)\n",
      "[2019-08-10 05:27:35,321] {basic_session_run_hooks.py:247} INFO - loss = 21.710125, step = 3101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.6\n",
      "[2019-08-10 05:27:35,551] {basic_session_run_hooks.py:680} INFO - global_step/sec: 417.6\n",
      "INFO:tensorflow:loss = 19.042223, step = 3201 (0.240 sec)\n",
      "[2019-08-10 05:27:35,562] {basic_session_run_hooks.py:247} INFO - loss = 19.042223, step = 3201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.393\n",
      "[2019-08-10 05:27:35,779] {basic_session_run_hooks.py:680} INFO - global_step/sec: 438.393\n",
      "INFO:tensorflow:loss = 15.420614, step = 3301 (0.225 sec)\n",
      "[2019-08-10 05:27:35,787] {basic_session_run_hooks.py:247} INFO - loss = 15.420614, step = 3301 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.542\n",
      "[2019-08-10 05:27:35,978] {basic_session_run_hooks.py:680} INFO - global_step/sec: 502.542\n",
      "INFO:tensorflow:loss = 14.3397875, step = 3401 (0.200 sec)\n",
      "[2019-08-10 05:27:35,987] {basic_session_run_hooks.py:247} INFO - loss = 14.3397875, step = 3401 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.808\n",
      "[2019-08-10 05:27:36,250] {basic_session_run_hooks.py:680} INFO - global_step/sec: 367.808\n",
      "INFO:tensorflow:loss = 15.886141, step = 3501 (0.275 sec)\n",
      "[2019-08-10 05:27:36,262] {basic_session_run_hooks.py:247} INFO - loss = 15.886141, step = 3501 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.049\n",
      "[2019-08-10 05:27:36,497] {basic_session_run_hooks.py:680} INFO - global_step/sec: 404.049\n",
      "INFO:tensorflow:loss = 17.138615, step = 3601 (0.244 sec)\n",
      "[2019-08-10 05:27:36,506] {basic_session_run_hooks.py:247} INFO - loss = 17.138615, step = 3601 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.634\n",
      "[2019-08-10 05:27:36,691] {basic_session_run_hooks.py:680} INFO - global_step/sec: 517.634\n",
      "INFO:tensorflow:loss = 17.654655, step = 3701 (0.194 sec)\n",
      "[2019-08-10 05:27:36,700] {basic_session_run_hooks.py:247} INFO - loss = 17.654655, step = 3701 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.95\n",
      "[2019-08-10 05:27:36,927] {basic_session_run_hooks.py:680} INFO - global_step/sec: 422.95\n",
      "INFO:tensorflow:loss = 15.680695, step = 3801 (0.236 sec)\n",
      "[2019-08-10 05:27:36,935] {basic_session_run_hooks.py:247} INFO - loss = 15.680695, step = 3801 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.483\n",
      "[2019-08-10 05:27:37,172] {basic_session_run_hooks.py:680} INFO - global_step/sec: 408.483\n",
      "INFO:tensorflow:loss = 14.118844, step = 3901 (0.244 sec)\n",
      "[2019-08-10 05:27:37,179] {basic_session_run_hooks.py:247} INFO - loss = 14.118844, step = 3901 (0.244 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3996 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m3996\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "[2019-08-10 05:27:37,601] {training.py:525} INFO - Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 220.947\n",
      "[2019-08-10 05:27:37,624] {basic_session_run_hooks.py:680} INFO - global_step/sec: 220.947\n",
      "INFO:tensorflow:loss = 16.706417, step = 4001 (0.456 sec)\n",
      "[2019-08-10 05:27:37,635] {basic_session_run_hooks.py:247} INFO - loss = 16.706417, step = 4001 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.055\n",
      "[2019-08-10 05:27:37,849] {basic_session_run_hooks.py:680} INFO - global_step/sec: 445.055\n",
      "INFO:tensorflow:loss = 14.986609, step = 4101 (0.224 sec)\n",
      "[2019-08-10 05:27:37,858] {basic_session_run_hooks.py:247} INFO - loss = 14.986609, step = 4101 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.796\n",
      "[2019-08-10 05:27:38,089] {basic_session_run_hooks.py:680} INFO - global_step/sec: 416.796\n",
      "INFO:tensorflow:loss = 13.410991, step = 4201 (0.240 sec)\n",
      "[2019-08-10 05:27:38,099] {basic_session_run_hooks.py:247} INFO - loss = 13.410991, step = 4201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.897\n",
      "[2019-08-10 05:27:38,339] {basic_session_run_hooks.py:680} INFO - global_step/sec: 399.897\n",
      "INFO:tensorflow:loss = 14.829353, step = 4301 (0.250 sec)\n",
      "[2019-08-10 05:27:38,348] {basic_session_run_hooks.py:247} INFO - loss = 14.829353, step = 4301 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.125\n",
      "[2019-08-10 05:27:38,580] {basic_session_run_hooks.py:680} INFO - global_step/sec: 414.125\n",
      "INFO:tensorflow:loss = 15.099603, step = 4401 (0.243 sec)\n",
      "[2019-08-10 05:27:38,591] {basic_session_run_hooks.py:247} INFO - loss = 15.099603, step = 4401 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.573\n",
      "[2019-08-10 05:27:38,832] {basic_session_run_hooks.py:680} INFO - global_step/sec: 397.573\n",
      "INFO:tensorflow:loss = 15.188459, step = 4501 (0.252 sec)\n",
      "[2019-08-10 05:27:38,843] {basic_session_run_hooks.py:247} INFO - loss = 15.188459, step = 4501 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.263\n",
      "[2019-08-10 05:27:39,079] {basic_session_run_hooks.py:680} INFO - global_step/sec: 405.263\n",
      "INFO:tensorflow:loss = 12.896591, step = 4601 (0.246 sec)\n",
      "[2019-08-10 05:27:39,088] {basic_session_run_hooks.py:247} INFO - loss = 12.896591, step = 4601 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.088\n",
      "[2019-08-10 05:27:39,311] {basic_session_run_hooks.py:680} INFO - global_step/sec: 430.088\n",
      "INFO:tensorflow:loss = 11.69946, step = 4701 (0.230 sec)\n",
      "[2019-08-10 05:27:39,319] {basic_session_run_hooks.py:247} INFO - loss = 11.69946, step = 4701 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.889\n",
      "[2019-08-10 05:27:39,558] {basic_session_run_hooks.py:680} INFO - global_step/sec: 405.889\n",
      "INFO:tensorflow:loss = 12.092059, step = 4801 (0.245 sec)\n",
      "[2019-08-10 05:27:39,564] {basic_session_run_hooks.py:247} INFO - loss = 12.092059, step = 4801 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.388\n",
      "[2019-08-10 05:27:39,774] {basic_session_run_hooks.py:680} INFO - global_step/sec: 461.388\n",
      "INFO:tensorflow:loss = 16.833239, step = 4901 (0.217 sec)\n",
      "[2019-08-10 05:27:39,781] {basic_session_run_hooks.py:247} INFO - loss = 16.833239, step = 4901 (0.217 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4995 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m4995\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "[2019-08-10 05:27:40,222] {training.py:525} INFO - Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 211.904\n",
      "[2019-08-10 05:27:40,246] {basic_session_run_hooks.py:680} INFO - global_step/sec: 211.904\n",
      "INFO:tensorflow:loss = 12.300641, step = 5001 (0.476 sec)\n",
      "[2019-08-10 05:27:40,257] {basic_session_run_hooks.py:247} INFO - loss = 12.300641, step = 5001 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.925\n",
      "[2019-08-10 05:27:40,503] {basic_session_run_hooks.py:680} INFO - global_step/sec: 388.925\n",
      "INFO:tensorflow:loss = 17.137775, step = 5101 (0.256 sec)\n",
      "[2019-08-10 05:27:40,513] {basic_session_run_hooks.py:247} INFO - loss = 17.137775, step = 5101 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.544\n",
      "[2019-08-10 05:27:40,743] {basic_session_run_hooks.py:680} INFO - global_step/sec: 417.544\n",
      "INFO:tensorflow:loss = 12.80236, step = 5201 (0.239 sec)\n",
      "[2019-08-10 05:27:40,752] {basic_session_run_hooks.py:247} INFO - loss = 12.80236, step = 5201 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.728\n",
      "[2019-08-10 05:27:40,951] {basic_session_run_hooks.py:680} INFO - global_step/sec: 481.728\n",
      "INFO:tensorflow:loss = 17.676348, step = 5301 (0.206 sec)\n",
      "[2019-08-10 05:27:40,957] {basic_session_run_hooks.py:247} INFO - loss = 17.676348, step = 5301 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.651\n",
      "[2019-08-10 05:27:41,136] {basic_session_run_hooks.py:680} INFO - global_step/sec: 540.651\n",
      "INFO:tensorflow:loss = 12.138985, step = 5401 (0.185 sec)\n",
      "[2019-08-10 05:27:41,143] {basic_session_run_hooks.py:247} INFO - loss = 12.138985, step = 5401 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.096\n",
      "[2019-08-10 05:27:41,320] {basic_session_run_hooks.py:680} INFO - global_step/sec: 543.096\n",
      "INFO:tensorflow:loss = 17.203068, step = 5501 (0.185 sec)\n",
      "[2019-08-10 05:27:41,328] {basic_session_run_hooks.py:247} INFO - loss = 17.203068, step = 5501 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.969\n",
      "[2019-08-10 05:27:41,512] {basic_session_run_hooks.py:680} INFO - global_step/sec: 519.969\n",
      "INFO:tensorflow:loss = 15.112465, step = 5601 (0.193 sec)\n",
      "[2019-08-10 05:27:41,521] {basic_session_run_hooks.py:247} INFO - loss = 15.112465, step = 5601 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 548.912\n",
      "[2019-08-10 05:27:41,694] {basic_session_run_hooks.py:680} INFO - global_step/sec: 548.912\n",
      "INFO:tensorflow:loss = 15.655186, step = 5701 (0.181 sec)\n",
      "[2019-08-10 05:27:41,701] {basic_session_run_hooks.py:247} INFO - loss = 15.655186, step = 5701 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 548.08\n",
      "[2019-08-10 05:27:41,919] {basic_session_run_hooks.py:680} INFO - global_step/sec: 548.08\n",
      "INFO:tensorflow:loss = 13.016251, step = 5801 (0.229 sec)\n",
      "[2019-08-10 05:27:41,931] {basic_session_run_hooks.py:247} INFO - loss = 13.016251, step = 5801 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.909\n",
      "[2019-08-10 05:27:42,157] {basic_session_run_hooks.py:680} INFO - global_step/sec: 356.909\n",
      "INFO:tensorflow:loss = 13.308071, step = 5901 (0.234 sec)\n",
      "[2019-08-10 05:27:42,165] {basic_session_run_hooks.py:247} INFO - loss = 13.308071, step = 5901 (0.234 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5994 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m5994\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "[2019-08-10 05:27:42,593] {training.py:525} INFO - Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 216.047\n",
      "[2019-08-10 05:27:42,620] {basic_session_run_hooks.py:680} INFO - global_step/sec: 216.047\n",
      "INFO:tensorflow:loss = 12.756512, step = 6001 (0.465 sec)\n",
      "[2019-08-10 05:27:42,630] {basic_session_run_hooks.py:247} INFO - loss = 12.756512, step = 6001 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.283\n",
      "[2019-08-10 05:27:42,847] {basic_session_run_hooks.py:680} INFO - global_step/sec: 439.283\n",
      "INFO:tensorflow:loss = 12.464058, step = 6101 (0.227 sec)\n",
      "[2019-08-10 05:27:42,858] {basic_session_run_hooks.py:247} INFO - loss = 12.464058, step = 6101 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.081\n",
      "[2019-08-10 05:27:43,096] {basic_session_run_hooks.py:680} INFO - global_step/sec: 402.081\n",
      "INFO:tensorflow:loss = 12.855694, step = 6201 (0.249 sec)\n",
      "[2019-08-10 05:27:43,106] {basic_session_run_hooks.py:247} INFO - loss = 12.855694, step = 6201 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.218\n",
      "[2019-08-10 05:27:43,344] {basic_session_run_hooks.py:680} INFO - global_step/sec: 403.218\n",
      "INFO:tensorflow:loss = 9.987341, step = 6301 (0.247 sec)\n",
      "[2019-08-10 05:27:43,354] {basic_session_run_hooks.py:247} INFO - loss = 9.987341, step = 6301 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.603\n",
      "[2019-08-10 05:27:43,596] {basic_session_run_hooks.py:680} INFO - global_step/sec: 396.603\n",
      "INFO:tensorflow:loss = 10.769022, step = 6401 (0.252 sec)\n",
      "[2019-08-10 05:27:43,605] {basic_session_run_hooks.py:247} INFO - loss = 10.769022, step = 6401 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.849\n",
      "[2019-08-10 05:27:43,840] {basic_session_run_hooks.py:680} INFO - global_step/sec: 410.849\n",
      "INFO:tensorflow:loss = 13.462256, step = 6501 (0.246 sec)\n",
      "[2019-08-10 05:27:43,851] {basic_session_run_hooks.py:247} INFO - loss = 13.462256, step = 6501 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.1\n",
      "[2019-08-10 05:27:44,090] {basic_session_run_hooks.py:680} INFO - global_step/sec: 399.1\n",
      "INFO:tensorflow:loss = 13.562706, step = 6601 (0.247 sec)\n",
      "[2019-08-10 05:27:44,098] {basic_session_run_hooks.py:247} INFO - loss = 13.562706, step = 6601 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.23\n",
      "[2019-08-10 05:27:44,331] {basic_session_run_hooks.py:680} INFO - global_step/sec: 415.23\n",
      "INFO:tensorflow:loss = 11.661724, step = 6701 (0.240 sec)\n",
      "[2019-08-10 05:27:44,338] {basic_session_run_hooks.py:247} INFO - loss = 11.661724, step = 6701 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.996\n",
      "[2019-08-10 05:27:44,562] {basic_session_run_hooks.py:680} INFO - global_step/sec: 432.996\n",
      "INFO:tensorflow:loss = 13.8362875, step = 6801 (0.233 sec)\n",
      "[2019-08-10 05:27:44,571] {basic_session_run_hooks.py:247} INFO - loss = 13.8362875, step = 6801 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.867\n",
      "[2019-08-10 05:27:44,778] {basic_session_run_hooks.py:680} INFO - global_step/sec: 462.867\n",
      "INFO:tensorflow:loss = 14.816349, step = 6901 (0.215 sec)\n",
      "[2019-08-10 05:27:44,786] {basic_session_run_hooks.py:247} INFO - loss = 14.816349, step = 6901 (0.215 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6993 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m6993\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "[2019-08-10 05:27:45,212] {training.py:525} INFO - Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 217.229\n",
      "[2019-08-10 05:27:45,238] {basic_session_run_hooks.py:680} INFO - global_step/sec: 217.229\n",
      "INFO:tensorflow:loss = 13.076738, step = 7001 (0.462 sec)\n",
      "[2019-08-10 05:27:45,248] {basic_session_run_hooks.py:247} INFO - loss = 13.076738, step = 7001 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.934\n",
      "[2019-08-10 05:27:45,466] {basic_session_run_hooks.py:680} INFO - global_step/sec: 439.934\n",
      "INFO:tensorflow:loss = 10.25231, step = 7101 (0.227 sec)\n",
      "[2019-08-10 05:27:45,475] {basic_session_run_hooks.py:247} INFO - loss = 10.25231, step = 7101 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.814\n",
      "[2019-08-10 05:27:45,710] {basic_session_run_hooks.py:680} INFO - global_step/sec: 408.814\n",
      "INFO:tensorflow:loss = 16.865252, step = 7201 (0.243 sec)\n",
      "[2019-08-10 05:27:45,718] {basic_session_run_hooks.py:247} INFO - loss = 16.865252, step = 7201 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.523\n",
      "[2019-08-10 05:27:45,943] {basic_session_run_hooks.py:680} INFO - global_step/sec: 429.523\n",
      "INFO:tensorflow:loss = 20.982592, step = 7301 (0.234 sec)\n",
      "[2019-08-10 05:27:45,952] {basic_session_run_hooks.py:247} INFO - loss = 20.982592, step = 7301 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.771\n",
      "[2019-08-10 05:27:46,170] {basic_session_run_hooks.py:680} INFO - global_step/sec: 439.771\n",
      "INFO:tensorflow:loss = 13.48996, step = 7401 (0.226 sec)\n",
      "[2019-08-10 05:27:46,179] {basic_session_run_hooks.py:247} INFO - loss = 13.48996, step = 7401 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.203\n",
      "[2019-08-10 05:27:46,417] {basic_session_run_hooks.py:680} INFO - global_step/sec: 406.203\n",
      "INFO:tensorflow:loss = 12.305752, step = 7501 (0.247 sec)\n",
      "[2019-08-10 05:27:46,426] {basic_session_run_hooks.py:247} INFO - loss = 12.305752, step = 7501 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.891\n",
      "[2019-08-10 05:27:46,622] {basic_session_run_hooks.py:680} INFO - global_step/sec: 487.891\n",
      "INFO:tensorflow:loss = 13.969092, step = 7601 (0.205 sec)\n",
      "[2019-08-10 05:27:46,631] {basic_session_run_hooks.py:247} INFO - loss = 13.969092, step = 7601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.502\n",
      "[2019-08-10 05:27:46,846] {basic_session_run_hooks.py:680} INFO - global_step/sec: 444.502\n",
      "INFO:tensorflow:loss = 14.581633, step = 7701 (0.226 sec)\n",
      "[2019-08-10 05:27:46,857] {basic_session_run_hooks.py:247} INFO - loss = 14.581633, step = 7701 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.494\n",
      "[2019-08-10 05:27:47,066] {basic_session_run_hooks.py:680} INFO - global_step/sec: 456.494\n",
      "INFO:tensorflow:loss = 13.036411, step = 7801 (0.218 sec)\n",
      "[2019-08-10 05:27:47,075] {basic_session_run_hooks.py:247} INFO - loss = 13.036411, step = 7801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.486\n",
      "[2019-08-10 05:27:47,277] {basic_session_run_hooks.py:680} INFO - global_step/sec: 473.486\n",
      "INFO:tensorflow:loss = 9.904701, step = 7901 (0.210 sec)\n",
      "[2019-08-10 05:27:47,285] {basic_session_run_hooks.py:247} INFO - loss = 9.904701, step = 7901 (0.210 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7992 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m7992\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "[2019-08-10 05:27:47,687] {training.py:525} INFO - Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 227.218\n",
      "[2019-08-10 05:27:47,717] {basic_session_run_hooks.py:680} INFO - global_step/sec: 227.218\n",
      "INFO:tensorflow:loss = 13.562122, step = 8001 (0.443 sec)\n",
      "[2019-08-10 05:27:47,728] {basic_session_run_hooks.py:247} INFO - loss = 13.562122, step = 8001 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.706\n",
      "[2019-08-10 05:27:47,945] {basic_session_run_hooks.py:680} INFO - global_step/sec: 438.706\n",
      "INFO:tensorflow:loss = 10.641089, step = 8101 (0.227 sec)\n",
      "[2019-08-10 05:27:47,955] {basic_session_run_hooks.py:247} INFO - loss = 10.641089, step = 8101 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.461\n",
      "[2019-08-10 05:27:48,180] {basic_session_run_hooks.py:680} INFO - global_step/sec: 425.461\n",
      "INFO:tensorflow:loss = 13.488853, step = 8201 (0.234 sec)\n",
      "[2019-08-10 05:27:48,189] {basic_session_run_hooks.py:247} INFO - loss = 13.488853, step = 8201 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.662\n",
      "[2019-08-10 05:27:48,496] {basic_session_run_hooks.py:680} INFO - global_step/sec: 316.662\n",
      "INFO:tensorflow:loss = 15.915246, step = 8301 (0.316 sec)\n",
      "[2019-08-10 05:27:48,505] {basic_session_run_hooks.py:247} INFO - loss = 15.915246, step = 8301 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.861\n",
      "[2019-08-10 05:27:48,742] {basic_session_run_hooks.py:680} INFO - global_step/sec: 405.861\n",
      "INFO:tensorflow:loss = 13.750379, step = 8401 (0.247 sec)\n",
      "[2019-08-10 05:27:48,753] {basic_session_run_hooks.py:247} INFO - loss = 13.750379, step = 8401 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.036\n",
      "[2019-08-10 05:27:49,034] {basic_session_run_hooks.py:680} INFO - global_step/sec: 342.036\n",
      "INFO:tensorflow:loss = 14.949293, step = 8501 (0.291 sec)\n",
      "[2019-08-10 05:27:49,044] {basic_session_run_hooks.py:247} INFO - loss = 14.949293, step = 8501 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.391\n",
      "[2019-08-10 05:27:49,261] {basic_session_run_hooks.py:680} INFO - global_step/sec: 441.391\n",
      "INFO:tensorflow:loss = 14.4606, step = 8601 (0.226 sec)\n",
      "[2019-08-10 05:27:49,270] {basic_session_run_hooks.py:247} INFO - loss = 14.4606, step = 8601 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.429\n",
      "[2019-08-10 05:27:49,505] {basic_session_run_hooks.py:680} INFO - global_step/sec: 410.429\n",
      "INFO:tensorflow:loss = 12.044443, step = 8701 (0.245 sec)\n",
      "[2019-08-10 05:27:49,515] {basic_session_run_hooks.py:247} INFO - loss = 12.044443, step = 8701 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.475\n",
      "[2019-08-10 05:27:49,746] {basic_session_run_hooks.py:680} INFO - global_step/sec: 414.475\n",
      "INFO:tensorflow:loss = 10.8900385, step = 8801 (0.242 sec)\n",
      "[2019-08-10 05:27:49,757] {basic_session_run_hooks.py:247} INFO - loss = 10.8900385, step = 8801 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.002\n",
      "[2019-08-10 05:27:49,980] {basic_session_run_hooks.py:680} INFO - global_step/sec: 427.002\n",
      "INFO:tensorflow:loss = 13.1797905, step = 8901 (0.231 sec)\n",
      "[2019-08-10 05:27:49,988] {basic_session_run_hooks.py:247} INFO - loss = 13.1797905, step = 8901 (0.231 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8991 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m8991\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "[2019-08-10 05:27:50,385] {training.py:525} INFO - Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 229.756\n",
      "[2019-08-10 05:27:50,415] {basic_session_run_hooks.py:680} INFO - global_step/sec: 229.756\n",
      "INFO:tensorflow:loss = 12.518463, step = 9001 (0.435 sec)\n",
      "[2019-08-10 05:27:50,424] {basic_session_run_hooks.py:247} INFO - loss = 12.518463, step = 9001 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.582\n",
      "[2019-08-10 05:27:50,631] {basic_session_run_hooks.py:680} INFO - global_step/sec: 463.582\n",
      "INFO:tensorflow:loss = 13.041484, step = 9101 (0.216 sec)\n",
      "[2019-08-10 05:27:50,639] {basic_session_run_hooks.py:247} INFO - loss = 13.041484, step = 9101 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.149\n",
      "[2019-08-10 05:27:50,872] {basic_session_run_hooks.py:680} INFO - global_step/sec: 415.149\n",
      "INFO:tensorflow:loss = 14.429088, step = 9201 (0.242 sec)\n",
      "[2019-08-10 05:27:50,881] {basic_session_run_hooks.py:247} INFO - loss = 14.429088, step = 9201 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.24\n",
      "[2019-08-10 05:27:51,119] {basic_session_run_hooks.py:680} INFO - global_step/sec: 404.24\n",
      "INFO:tensorflow:loss = 14.187693, step = 9301 (0.247 sec)\n",
      "[2019-08-10 05:27:51,128] {basic_session_run_hooks.py:247} INFO - loss = 14.187693, step = 9301 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.358\n",
      "[2019-08-10 05:27:51,337] {basic_session_run_hooks.py:680} INFO - global_step/sec: 458.358\n",
      "INFO:tensorflow:loss = 13.04789, step = 9401 (0.218 sec)\n",
      "[2019-08-10 05:27:51,347] {basic_session_run_hooks.py:247} INFO - loss = 13.04789, step = 9401 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.166\n",
      "[2019-08-10 05:27:51,580] {basic_session_run_hooks.py:680} INFO - global_step/sec: 412.166\n",
      "INFO:tensorflow:loss = 14.082392, step = 9501 (0.243 sec)\n",
      "[2019-08-10 05:27:51,589] {basic_session_run_hooks.py:247} INFO - loss = 14.082392, step = 9501 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.872\n",
      "[2019-08-10 05:27:51,803] {basic_session_run_hooks.py:680} INFO - global_step/sec: 448.872\n",
      "INFO:tensorflow:loss = 13.501836, step = 9601 (0.225 sec)\n",
      "[2019-08-10 05:27:51,815] {basic_session_run_hooks.py:247} INFO - loss = 13.501836, step = 9601 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.123\n",
      "[2019-08-10 05:27:52,058] {basic_session_run_hooks.py:680} INFO - global_step/sec: 392.123\n",
      "INFO:tensorflow:loss = 13.421159, step = 9701 (0.253 sec)\n",
      "[2019-08-10 05:27:52,068] {basic_session_run_hooks.py:247} INFO - loss = 13.421159, step = 9701 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.398\n",
      "[2019-08-10 05:27:52,303] {basic_session_run_hooks.py:680} INFO - global_step/sec: 407.398\n",
      "INFO:tensorflow:loss = 15.001509, step = 9801 (0.244 sec)\n",
      "[2019-08-10 05:27:52,312] {basic_session_run_hooks.py:247} INFO - loss = 15.001509, step = 9801 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.677\n",
      "[2019-08-10 05:27:52,518] {basic_session_run_hooks.py:680} INFO - global_step/sec: 464.677\n",
      "INFO:tensorflow:loss = 13.815689, step = 9901 (0.219 sec)\n",
      "[2019-08-10 05:27:52,531] {basic_session_run_hooks.py:247} INFO - loss = 13.815689, step = 9901 (0.219 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9990 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 582, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m9990\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "[2019-08-10 05:27:52,900] {training.py:525} INFO - Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 588, in end\n",
      "    self._save(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 594, in _save\n",
      "    logging.info(\"Saving checkpoints for %d into %s.\", step, self._save_path)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Saving checkpoints for %d into %s.'\n",
      "Arguments: ('\\x1b[1m10000\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "[2019-08-10 05:27:53,130] {training.py:525} INFO - Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "[2019-08-10 05:27:53,206] {estimator.py:1111} INFO - Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "[2019-08-10 05:27:54,506] {metrics_impl.py:783} WARNING - Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "[2019-08-10 05:27:54,531] {metrics_impl.py:783} WARNING - Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "[2019-08-10 05:27:54,555] {estimator.py:1113} INFO - Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-08-10T05:27:54Z\n",
      "[2019-08-10 05:27:54,577] {evaluation.py:257} INFO - Starting evaluation at 2019-08-10T05:27:54Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "[2019-08-10 05:27:54,742] {monitored_session.py:222} INFO - Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-10000\n",
      "[2019-08-10 05:27:54,750] {saver.py:1270} INFO - Restoring parameters from /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "[2019-08-10 05:27:54,834] {session_manager.py:491} INFO - Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[2019-08-10 05:27:54,871] {session_manager.py:493} INFO - Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [500/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m500\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1000/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m1000\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1500/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m1500\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2000/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m2000\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2500/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m2500\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3000/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m3000\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3500/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m3500\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4000/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m4000\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4500/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m4500\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5000/5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1537, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 274, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n",
      "    run_metadata=run_metadata)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1335, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/evaluation.py\", line 169, in after_run\n",
      "    logging.info('Evaluation [%d/%d]', evals_completed, self._num_evals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: 'Evaluation [%d/%d]'\n",
      "Arguments: ('\\x1b[1m5000\\x1b[0m', 5000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-08-10-05:28:07\n",
      "[2019-08-10 05:28:07,407] {evaluation.py:277} INFO - Finished evaluation at 2019-08-10-05:28:07\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.794745, accuracy_baseline = 0.769645, auc = 0.9465486, auc_precision_recall = 0.74190515, average_loss = 0.33508867, global_step = 10000, label/mean = 0.230355, loss = 13.403547, precision = 0.7235085, prediction/mean = 0.2258133, recall = 0.17635822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1544, in _evaluate_run\n",
      "    current_global_step=current_global_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1979, in _write_dict_to_summary\n",
      "    _dict_to_str(dictionary))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Message: 'Saving dict for global step %d: %s'\n",
      "Arguments: ('\\x1b[1m10000\\x1b[0m', '\\x1b[1maccuracy = 0.794745, accuracy_baseline = 0.769645, auc = 0.9465486, auc_precision_recall = 0.74190515, average_loss = 0.33508867, global_step = 10000, label/mean = 0.230355, loss = 13.403547, precision = 0.7235085, prediction/mean = 0.2258133, recall = 0.17635822\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 980, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 830, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/airflow/utils/log/colored_log.py\", line 82, in format\n",
      "    return super(CustomTTYColoredFormatter, self).format(record)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/colorlog/colorlog.py\", line 119, in format\n",
      "    message = super(ColoredFormatter, self).format(record)\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 567, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/lib/python3.5/logging/__init__.py\", line 330, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: %d format: a number is required, not str\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 708, in __init__\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2ed351cd6fd7>\", line 1, in <module>\n",
      "    pipeline = DirectRunner().run(pipeline)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 9, in run\n",
      "    self._execute_component(component)\n",
      "  File \"<ipython-input-16-ab40567aafec>\", line 18, in _execute_component\n",
      "    executor.Do(input_dict, output_dict, exec_properties)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tfx/components/trainer/executor.py\", line 144, in Do\n",
      "    training_spec['eval_spec'])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 611, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 712, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1408, in _train_with_estimator_spec\n",
      "    any_step_done = True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 788, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 821, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 590, in end\n",
      "    l.end(session, last_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 531, in end\n",
      "    self._evaluate(global_step_value)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 913, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 469, in evaluate\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 500, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1550, in _evaluate_run\n",
      "    current_global_step=current_global_step)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 2039, in _write_checkpoint_path_to_summary\n",
      "    checkpoint_path_tag, current_global_step, checkpoint_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/tf_logging.py\", line 156, in info\n",
      "    get_logger().info(msg, *args, **kwargs)\n",
      "Message: \"Saving '%s' summary for global step %d: %s\"\n",
      "Arguments: ('\\x1b[1mcheckpoint_path\\x1b[0m', '\\x1b[1m10000\\x1b[0m', '\\x1b[1m/root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-10000\\x1b[0m')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "[2019-08-10 05:28:07,512] {exporter.py:415} INFO - Performing the final export in the end of training.\n",
      "WARNING:tensorflow:partially_apply_saved_transform is deprecated.  Use the transform_raw_features method of the TFTrandformOutput class instead.\n",
      "[2019-08-10 05:28:07,559] {tf_logging.py:161} WARNING - partially_apply_saved_transform is deprecated.  Use the transform_raw_features method of the TFTrandformOutput class instead.\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "[2019-08-10 05:28:07,649] {ops.py:6153} WARNING - Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "[2019-08-10 05:28:07,655] {ops.py:6153} WARNING - Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:28:07,660] {saver.py:1483} INFO - Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "[2019-08-10 05:28:07,670] {estimator.py:1111} INFO - Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "[2019-08-10 05:28:08,695] {estimator.py:1113} INFO - Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['classification', 'serving_default']\n",
      "[2019-08-10 05:28:08,702] {export.py:587} INFO - Signatures INCLUDED in export for Classify: ['classification', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "[2019-08-10 05:28:08,707] {export.py:587} INFO - Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "[2019-08-10 05:28:08,716] {export.py:587} INFO - Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n",
      "[2019-08-10 05:28:08,723] {export.py:587} INFO - Signatures INCLUDED in export for Regress: ['regression']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "[2019-08-10 05:28:08,728] {export.py:587} INFO - Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Restoring parameters from /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-10000\n",
      "[2019-08-10 05:28:08,839] {saver.py:1270} INFO - Restoring parameters from /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-10000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "[2019-08-10 05:28:08,889] {builder_impl.py:654} INFO - Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: /root/taxi/data/simple/trainer/current/serving_model_dir/export/chicago-taxi/temp-b'1565414887'/assets\n",
      "[2019-08-10 05:28:08,896] {builder_impl.py:763} INFO - Assets written to: /root/taxi/data/simple/trainer/current/serving_model_dir/export/chicago-taxi/temp-b'1565414887'/assets\n",
      "INFO:tensorflow:SavedModel written to: /root/taxi/data/simple/trainer/current/serving_model_dir/export/chicago-taxi/temp-b'1565414887'/saved_model.pb\n",
      "[2019-08-10 05:28:09,093] {builder_impl.py:414} INFO - SavedModel written to: /root/taxi/data/simple/trainer/current/serving_model_dir/export/chicago-taxi/temp-b'1565414887'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 13.266011.\n",
      "[2019-08-10 05:28:09,275] {estimator.py:359} INFO - Loss for final step: 13.266011.\n",
      "INFO:tensorflow:Training complete.  Model written to /root/taxi/data/simple/trainer/current/serving_model_dir\n",
      "[2019-08-10 05:28:09,290] {executor.py:146} INFO - Training complete.  Model written to /root/taxi/data/simple/trainer/current/serving_model_dir\n",
      "INFO:tensorflow:Exporting eval_savedmodel for TFMA.\n",
      "[2019-08-10 05:28:09,304] {executor.py:149} INFO - Exporting eval_savedmodel for TFMA.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_model_analysis/eval_saved_model/export.py:476: export_all_saved_models (from tensorflow_estimator.contrib.estimator.python.estimator.export) is deprecated and will be removed after 2018-12-03.\n",
      "Instructions for updating:\n",
      "Use estimator.experimental_export_all_saved_models\n",
      "[2019-08-10 05:28:09,313] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow_model_analysis/eval_saved_model/export.py:476: export_all_saved_models (from tensorflow_estimator.contrib.estimator.python.estimator.export) is deprecated and will be removed after 2018-12-03.\n",
      "Instructions for updating:\n",
      "Use estimator.experimental_export_all_saved_models\n",
      "WARNING:tensorflow:partially_apply_saved_transform is deprecated.  Use the transform_raw_features method of the TFTrandformOutput class instead.\n",
      "[2019-08-10 05:28:09,347] {tf_logging.py:161} WARNING - partially_apply_saved_transform is deprecated.  Use the transform_raw_features method of the TFTrandformOutput class instead.\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "[2019-08-10 05:28:09,416] {ops.py:6153} WARNING - Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022-vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "[2019-08-10 05:28:09,421] {ops.py:6153} WARNING - Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_6:0\\022/vocab_compute_and_apply_vocabulary_1_vocabulary\"\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "[2019-08-10 05:28:09,430] {saver.py:1483} INFO - Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "[2019-08-10 05:28:09,477] {estimator.py:1111} INFO - Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "[2019-08-10 05:28:11,133] {metrics_impl.py:783} WARNING - Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "[2019-08-10 05:28:11,161] {metrics_impl.py:783} WARNING - Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "[2019-08-10 05:28:11,188] {estimator.py:1113} INFO - Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "[2019-08-10 05:28:11,198] {export.py:587} INFO - Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: ['eval']\n",
      "[2019-08-10 05:28:11,208] {export.py:587} INFO - Signatures INCLUDED in export for Eval: ['eval']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "[2019-08-10 05:28:11,214] {export.py:587} INFO - Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "[2019-08-10 05:28:11,223] {export.py:587} INFO - Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: None\n",
      "[2019-08-10 05:28:11,229] {export.py:587} INFO - Signatures INCLUDED in export for Predict: None\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "[2019-08-10 05:28:11,235] {tf_logging.py:161} WARNING - Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:28:11,348] {saver.py:1270} INFO - Restoring parameters from /root/taxi/data/simple/trainer/current/serving_model_dir/model.ckpt-10000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "[2019-08-10 05:28:11,437] {builder_impl.py:654} INFO - Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: /root/taxi/data/simple/trainer/current/eval_model_dir/temp-b'1565414889'/assets\n",
      "[2019-08-10 05:28:11,449] {builder_impl.py:763} INFO - Assets written to: /root/taxi/data/simple/trainer/current/eval_model_dir/temp-b'1565414889'/assets\n",
      "INFO:tensorflow:SavedModel written to: /root/taxi/data/simple/trainer/current/eval_model_dir/temp-b'1565414889'/saved_model.pb\n",
      "[2019-08-10 05:28:11,795] {builder_impl.py:414} INFO - SavedModel written to: /root/taxi/data/simple/trainer/current/eval_model_dir/temp-b'1565414889'/saved_model.pb\n",
      "INFO:tensorflow:Exported eval_savedmodel to /root/taxi/data/simple/trainer/current/eval_model_dir.\n",
      "[2019-08-10 05:28:11,813] {executor.py:155} INFO - Exported eval_savedmodel to /root/taxi/data/simple/trainer/current/eval_model_dir.\n",
      "INFO:tensorflow:Starting Executor execution.\n",
      "[2019-08-10 05:28:11,830] {base_executor.py:72} INFO - Starting Executor execution.\n",
      "INFO:tensorflow:Inputs for Executor is: {\"examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"model_exports\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ModelExportPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple/trainer/current/\"}, \"artifact_type\": {\"name\": \"ModelExportPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "[2019-08-10 05:28:11,837] {base_executor.py:74} INFO - Inputs for Executor is: {\"examples\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"train\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/train/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}, {\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ExamplesPath\"}, \"split\": {\"stringValue\": \"eval\"}}, \"uri\": \"/root/taxi/data/simple/csv_example_gen/eval/\"}, \"artifact_type\": {\"name\": \"ExamplesPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}], \"model_exports\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ModelExportPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple/trainer/current/\"}, \"artifact_type\": {\"name\": \"ModelExportPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "INFO:tensorflow:Outputs for Executor is: {\"output\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ModelEvalPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple/eval_output/\"}, \"artifact_type\": {\"name\": \"ModelEvalPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "[2019-08-10 05:28:11,848] {base_executor.py:76} INFO - Outputs for Executor is: {\"output\": [{\"artifact\": {\"properties\": {\"type_name\": {\"stringValue\": \"ModelEvalPath\"}, \"split\": {\"stringValue\": \"\"}}, \"uri\": \"/root/taxi/data/simple/eval_output/\"}, \"artifact_type\": {\"name\": \"ModelEvalPath\", \"properties\": {\"span\": \"INT\", \"type_name\": \"STRING\", \"split\": \"STRING\", \"name\": \"STRING\", \"state\": \"STRING\"}}}]}\n",
      "INFO:tensorflow:Execution properties for Executor is: {\"feature_slicing_spec\": \"{\\n  \\\"specs\\\": [\\n    {\\n      \\\"columnForSlicing\\\": [\\n        \\\"trip_start_hour\\\"\\n      ]\\n    }\\n  ]\\n}\"}\n",
      "[2019-08-10 05:28:11,854] {base_executor.py:78} INFO - Execution properties for Executor is: {\"feature_slicing_spec\": \"{\\n  \\\"specs\\\": [\\n    {\\n      \\\"columnForSlicing\\\": [\\n        \\\"trip_start_hour\\\"\\n      ]\\n    }\\n  ]\\n}\"}\n",
      "INFO:tensorflow:Using /root/taxi/data/simple/trainer/current/eval_model_dir/1565414889 for model eval.\n",
      "[2019-08-10 05:28:11,865] {<ipython-input-14-a3725876ff5b>:48} INFO - Using /root/taxi/data/simple/trainer/current/eval_model_dir/1565414889 for model eval.\n",
      "INFO:tensorflow:Evaluating model.\n",
      "[2019-08-10 05:28:11,880] {<ipython-input-14-a3725876ff5b>:59} INFO - Evaluating model.\n",
      "[2019-08-10 05:28:11,890] {pipeline.py:143} INFO - Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow_model_analysis/slicer/slicer.py:407: BeamDeprecationWarning: RemoveDuplicates is deprecated since 2.12. Use Distinct instead.\n",
      "  | 'IncrementCounter' >> beam.Map(increment_counter))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:28:13,441] {fn_api_runner_transforms.py:488} INFO - ==================== <function annotate_downstream_side_inputs at 0x7f3cd6d6eae8> ====================\n",
      "[2019-08-10 05:28:13,457] {fn_api_runner_transforms.py:488} INFO - ==================== <function fix_side_input_pcoll_coders at 0x7f3cd6d6ebf8> ====================\n",
      "[2019-08-10 05:28:13,468] {fn_api_runner_transforms.py:488} INFO - ==================== <function lift_combiners at 0x7f3cd6d6ec80> ====================\n",
      "[2019-08-10 05:28:13,478] {fn_api_runner_transforms.py:488} INFO - ==================== <function expand_sdf at 0x7f3cd6d6ed08> ====================\n",
      "[2019-08-10 05:28:13,489] {fn_api_runner_transforms.py:488} INFO - ==================== <function expand_gbk at 0x7f3cd6d6ed90> ====================\n",
      "[2019-08-10 05:28:13,501] {fn_api_runner_transforms.py:488} INFO - ==================== <function sink_flattens at 0x7f3cd6d6eea0> ====================\n",
      "[2019-08-10 05:28:13,515] {fn_api_runner_transforms.py:488} INFO - ==================== <function greedily_fuse at 0x7f3cd6d6ef28> ====================\n",
      "[2019-08-10 05:28:13,531] {fn_api_runner_transforms.py:488} INFO - ==================== <function read_to_impulse at 0x7f3cd6d6f048> ====================\n",
      "[2019-08-10 05:28:13,543] {fn_api_runner_transforms.py:488} INFO - ==================== <function impulse_to_input at 0x7f3cd6d6f0d0> ====================\n",
      "[2019-08-10 05:28:13,554] {fn_api_runner_transforms.py:488} INFO - ==================== <function inject_timer_pcollections at 0x7f3cd6d6f268> ====================\n",
      "[2019-08-10 05:28:13,563] {fn_api_runner_transforms.py:488} INFO - ==================== <function sort_stages at 0x7f3cd6d6f2f0> ====================\n",
      "[2019-08-10 05:28:13,571] {fn_api_runner_transforms.py:488} INFO - ==================== <function window_pcollection_coders at 0x7f3cd6d6f378> ====================\n",
      "[2019-08-10 05:28:13,592] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_ReadData/Read_3)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/InputsToExtracts/Map(<lambda at model_eval_lib.py:393>)_6)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/Predict/Batch/ParDo(_GlobalWindowsBatchingDoFn)_10)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/Predict/Predict_11))))+(((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/ExtractSliceKeys/ParDo(_ExtractSliceKeysFn)_13)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/Filter/Map(filter_extracts)_16))+((((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/DoSlicing_19)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/ExtractSliceKeys_21)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/RemoveDuplicates/ToPairs_24)+((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/RemoveDuplicates/Group/Precombine)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/RemoveDuplicates/Group/Group/Write)))))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/ComputePerSliceMetrics/CombinePerSlice/Precombine))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/ComputePerSliceMetrics/CombinePerSlice/Group/Write)))\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_model_analysis/eval_saved_model/load.py:150: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "[2019-08-10 05:28:13,734] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow_model_analysis/eval_saved_model/load.py:150: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from /root/taxi/data/simple/trainer/current/eval_model_dir/1565414889/variables/variables\n",
      "[2019-08-10 05:28:14,693] {saver.py:1270} INFO - Restoring parameters from /root/taxi/data/simple/trainer/current/eval_model_dir/1565414889/variables/variables\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_model_analysis/eval_saved_model/graph_ref.py:189: get_tensor_from_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.get_tensor_from_tensor_info or tf.compat.v1.saved_model.get_tensor_from_tensor_info.\n",
      "[2019-08-10 05:28:14,843] {deprecation.py:323} WARNING - From /usr/local/lib/python3.5/dist-packages/tensorflow_model_analysis/eval_saved_model/graph_ref.py:189: get_tensor_from_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.get_tensor_from_tensor_info or tf.compat.v1.saved_model.get_tensor_from_tensor_info.\n",
      "[2019-08-10 05:28:24,733] {fn_api_runner.py:577} INFO - Running (ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/RemoveDuplicates/Group/Group/Read)+((((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/RemoveDuplicates/Group/Merge)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/RemoveDuplicates/Group/ExtractOutputs))+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/RemoveDuplicates/RemoveDuplicates/Distinct_32)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/KeyWithVoid_35)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Precombine))))+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Write))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:28:24,762] {fn_api_runner.py:577} INFO - Running ((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Group/Read)+((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/Merge)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/CombinePerKey/ExtractOutputs)))+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/UnKey_43)+(ref_PCollection_PCollection_20/Write))\n",
      "[2019-08-10 05:28:24,783] {fn_api_runner.py:577} INFO - Running (ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteEvalConfig(EvalConfig(model_location='/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889', data_location='<user provided PCollection>', slice_spec=[SingleSliceSpec(columns=frozenset({'trip_start_hour'}), features=frozenset()), SingleSliceSpec(columns=frozenset(), features=frozenset())], example_weight_metric_key='post_export_metrics/example_count', num_bootstrap_samples=1))/CreateEvalConfig/Read_97)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteEvalConfig(EvalConfig(model_location='/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889', data_location='<user provided PCollection>', slice_spec=[SingleSliceSpec(columns=frozenset({'trip_start_hour'}), features=frozenset()), SingleSliceSpec(columns=frozenset(), features=frozenset())], example_weight_metric_key='post_export_metrics/example_count', num_bootstrap_samples=1))/WriteEvalConfig/Write/WriteImpl/Map(<lambda at iobase.py:989>)_104)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteEvalConfig(EvalConfig(model_location='/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889', data_location='<user provided PCollection>', slice_spec=[SingleSliceSpec(columns=frozenset({'trip_start_hour'}), features=frozenset()), SingleSliceSpec(columns=frozenset(), features=frozenset())], example_weight_metric_key='post_export_metrics/example_count', num_bootstrap_samples=1))/WriteEvalConfig/Write/WriteImpl/WindowInto(WindowIntoFn)_105)+(ExtractEvaluateAndWriteResults/WriteEvalConfig(EvalConfig(model_location='/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889', data_location='<user provided PCollection>', slice_spec=[SingleSliceSpec(columns=frozenset({'trip_start_hour'}), features=frozenset()), SingleSliceSpec(columns=frozenset(), features=frozenset())], example_weight_metric_key='post_export_metrics/example_count', num_bootstrap_samples=1))/WriteEvalConfig/Write/WriteImpl/GroupByKey/Write)))\n",
      "[2019-08-10 05:28:24,810] {fn_api_runner.py:577} INFO - Running ((((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/ComputePerSliceMetrics/CombinePerSlice/Group/Read)+(((ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/ComputePerSliceMetrics/CombinePerSlice/Merge)+(ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/ComputePerSliceMetrics/CombinePerSlice/ExtractOutputs))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/ComputePerSliceMetrics/InterpretOutput_56)))+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/ComputePerSliceMetrics/ParDo(_SeparateMetricsAndPlotsFn)/ParDo(_SeparateMetricsAndPlotsFn)_58)+(((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/SerializeMetricsAndPlots/SerializeMetrics_60)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/metrics)/WriteToTFRecord/Write/WriteImpl/Map(<lambda at iobase.py:989>)_86))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/metrics)/WriteToTFRecord/Write/WriteImpl/WindowInto(WindowIntoFn)_87))))+(ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/metrics)/WriteToTFRecord/Write/WriteImpl/GroupByKey/Write))+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/SerializeMetricsAndPlots/SerializePlots_61)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/plots)/WriteToTFRecord/Write/WriteImpl/Map(<lambda at iobase.py:989>)_70)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/plots)/WriteToTFRecord/Write/WriteImpl/WindowInto(WindowIntoFn)_71)+(ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/plots)/WriteToTFRecord/Write/WriteImpl/GroupByKey/Write))))\n",
      "[2019-08-10 05:28:36,163] {fn_api_runner.py:577} INFO - Running (((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/metrics)/WriteToTFRecord/Write/WriteImpl/DoOnce/Read_84)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/metrics)/WriteToTFRecord/Write/WriteImpl/InitializeWrite_85))+(ref_PCollection_PCollection_43/Write))+(ref_PCollection_PCollection_44/Write)\n",
      "[2019-08-10 05:28:36,185] {fn_api_runner.py:577} INFO - Running (ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/metrics)/WriteToTFRecord/Write/WriteImpl/GroupByKey/Read)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/metrics)/WriteToTFRecord/Write/WriteImpl/WriteBundles_92)+(ref_PCollection_PCollection_50/Write))\n",
      "[2019-08-10 05:28:36,204] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/plots)/WriteToTFRecord/Write/WriteImpl/DoOnce/Read_68)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/plots)/WriteToTFRecord/Write/WriteImpl/InitializeWrite_69)+(ref_PCollection_PCollection_34/Write)))+(ref_PCollection_PCollection_33/Write)\n",
      "[2019-08-10 05:28:36,226] {fn_api_runner.py:577} INFO - Running (ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/plots)/WriteToTFRecord/Write/WriteImpl/GroupByKey/Read)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/plots)/WriteToTFRecord/Write/WriteImpl/WriteBundles_76)+(ref_PCollection_PCollection_40/Write))\n",
      "[2019-08-10 05:28:36,495] {fn_api_runner.py:577} INFO - Running ((ref_PCollection_PCollection_33/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/plots)/WriteToTFRecord/Write/WriteImpl/PreFinalize_77))+(ref_PCollection_PCollection_41/Write)\n",
      "[2019-08-10 05:28:36,515] {fn_api_runner.py:577} INFO - Running ((ref_PCollection_PCollection_43/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/metrics)/WriteToTFRecord/Write/WriteImpl/PreFinalize_93))+(ref_PCollection_PCollection_51/Write)\n",
      "[2019-08-10 05:28:36,534] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_43/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/metrics)/WriteToTFRecord/Write/WriteImpl/FinalizeWrite_94)\n",
      "[2019-08-10 05:28:36,549] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-08-10 05:28:36,658] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n",
      "[2019-08-10 05:28:36,685] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_33/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteResults/WriteTFRecord(/root/taxi/data/simple/eval_output/plots)/WriteToTFRecord/Write/WriteImpl/FinalizeWrite_78)\n",
      "[2019-08-10 05:28:36,703] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "[2019-08-10 05:28:36,811] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n",
      "[2019-08-10 05:28:36,836] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteEvalConfig(EvalConfig(model_location='/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889', data_location='<user provided PCollection>', slice_spec=[SingleSliceSpec(columns=frozenset({'trip_start_hour'}), features=frozenset()), SingleSliceSpec(columns=frozenset(), features=frozenset())], example_weight_metric_key='post_export_metrics/example_count', num_bootstrap_samples=1))/WriteEvalConfig/Write/WriteImpl/DoOnce/Read_102)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteEvalConfig(EvalConfig(model_location='/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889', data_location='<user provided PCollection>', slice_spec=[SingleSliceSpec(columns=frozenset({'trip_start_hour'}), features=frozenset()), SingleSliceSpec(columns=frozenset(), features=frozenset())], example_weight_metric_key='post_export_metrics/example_count', num_bootstrap_samples=1))/WriteEvalConfig/Write/WriteImpl/InitializeWrite_103)+(ref_PCollection_PCollection_55/Write)))+(ref_PCollection_PCollection_54/Write)\n",
      "[2019-08-10 05:28:36,858] {fn_api_runner.py:577} INFO - Running (ExtractEvaluateAndWriteResults/WriteEvalConfig(EvalConfig(model_location='/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889', data_location='<user provided PCollection>', slice_spec=[SingleSliceSpec(columns=frozenset({'trip_start_hour'}), features=frozenset()), SingleSliceSpec(columns=frozenset(), features=frozenset())], example_weight_metric_key='post_export_metrics/example_count', num_bootstrap_samples=1))/WriteEvalConfig/Write/WriteImpl/GroupByKey/Read)+((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteEvalConfig(EvalConfig(model_location='/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889', data_location='<user provided PCollection>', slice_spec=[SingleSliceSpec(columns=frozenset({'trip_start_hour'}), features=frozenset()), SingleSliceSpec(columns=frozenset(), features=frozenset())], example_weight_metric_key='post_export_metrics/example_count', num_bootstrap_samples=1))/WriteEvalConfig/Write/WriteImpl/WriteBundles_110)+(ref_PCollection_PCollection_61/Write))\n",
      "[2019-08-10 05:28:36,877] {fn_api_runner.py:577} INFO - Running ((ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/DoOnce/Read_45)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/Size/CombineGlobally(CountCombineFn)/InjectDefault_46))+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/ExtractAndEvaluate/EvaluateMetricsAndPlots/ComputeMetricsAndPlots/FanoutSlices/TrackDistinctSliceKeys/IncrementCounter_47)\n",
      "[2019-08-10 05:28:36,901] {fn_api_runner.py:577} INFO - Running ((ref_PCollection_PCollection_54/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteEvalConfig(EvalConfig(model_location='/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889', data_location='<user provided PCollection>', slice_spec=[SingleSliceSpec(columns=frozenset({'trip_start_hour'}), features=frozenset()), SingleSliceSpec(columns=frozenset(), features=frozenset())], example_weight_metric_key='post_export_metrics/example_count', num_bootstrap_samples=1))/WriteEvalConfig/Write/WriteImpl/PreFinalize_111))+(ref_PCollection_PCollection_62/Write)\n",
      "[2019-08-10 05:28:36,921] {fn_api_runner.py:577} INFO - Running (ref_PCollection_PCollection_54/Read)+(ref_AppliedPTransform_ExtractEvaluateAndWriteResults/WriteEvalConfig(EvalConfig(model_location='/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889', data_location='<user provided PCollection>', slice_spec=[SingleSliceSpec(columns=frozenset({'trip_start_hour'}), features=frozenset()), SingleSliceSpec(columns=frozenset(), features=frozenset())], example_weight_metric_key='post_export_metrics/example_count', num_bootstrap_samples=1))/WriteEvalConfig/Write/WriteImpl/FinalizeWrite_112)\n",
      "[2019-08-10 05:28:36,936] {filebasedsink.py:291} INFO - Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "[2019-08-10 05:28:37,045] {filebasedsink.py:328} INFO - Renamed 1 shards in 0.10 seconds.\n",
      "INFO:tensorflow:Evaluation complete. Results written to /root/taxi/data/simple/eval_output/.\n",
      "[2019-08-10 05:28:37,073] {<ipython-input-14-a3725876ff5b>:72} INFO - Evaluation complete. Results written to /root/taxi/data/simple/eval_output/.\n"
     ]
    }
   ],
   "source": [
    "pipeline = DirectRunner().run(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/taxi/data/simple/:\r\n",
      "total 1.9M\r\n",
      "4.0K drwxr-xr-x 4 root root 4.0K Aug 10 05:26 csv_example_gen\r\n",
      "1.9M -rw-r--r-- 1 root root 1.9M Aug 10 05:26 data.csv\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:28 eval_output\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:26 schema_gen\r\n",
      "4.0K drwxr-xr-x 4 root root 4.0K Aug 10 05:26 statistics_gen\r\n",
      "4.0K drwxr-xr-x 3 root root 4.0K Aug 10 05:27 trainer\r\n",
      "4.0K drwxr-xr-x 4 root root 4.0K Aug 10 05:27 transform\r\n",
      "\r\n",
      "/root/taxi/data/simple/csv_example_gen:\r\n",
      "total 8.0K\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:26 eval\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:26 train\r\n",
      "\r\n",
      "/root/taxi/data/simple/csv_example_gen/eval:\r\n",
      "total 204K\r\n",
      "204K -rw-r--r-- 1 root root 201K Aug 10 05:26 data_tfrecord-00000-of-00001.gz\r\n",
      "\r\n",
      "/root/taxi/data/simple/csv_example_gen/train:\r\n",
      "total 408K\r\n",
      "408K -rw-r--r-- 1 root root 406K Aug 10 05:26 data_tfrecord-00000-of-00001.gz\r\n",
      "\r\n",
      "/root/taxi/data/simple/eval_output:\r\n",
      "total 34M\r\n",
      "4.0K -rw-r--r-- 1 root root  506 Aug 10 05:28 eval_config\r\n",
      " 12K -rw-r--r-- 1 root root 8.4K Aug 10 05:28 metrics\r\n",
      " 34M -rw-r--r-- 1 root root  34M Aug 10 05:28 plots\r\n",
      "\r\n",
      "/root/taxi/data/simple/schema_gen:\r\n",
      "total 8.0K\r\n",
      "8.0K -rw-r--r-- 1 root root 4.5K Aug 10 05:26 schema.pbtxt\r\n",
      "\r\n",
      "/root/taxi/data/simple/statistics_gen:\r\n",
      "total 8.0K\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:26 eval\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:26 train\r\n",
      "\r\n",
      "/root/taxi/data/simple/statistics_gen/eval:\r\n",
      "total 20K\r\n",
      "20K -rw-r--r-- 1 root root 17K Aug 10 05:26 stats_tfrecord\r\n",
      "\r\n",
      "/root/taxi/data/simple/statistics_gen/train:\r\n",
      "total 20K\r\n",
      "20K -rw-r--r-- 1 root root 18K Aug 10 05:26 stats_tfrecord\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer:\r\n",
      "total 4.0K\r\n",
      "4.0K drwxr-xr-x 4 root root 4.0K Aug 10 05:28 current\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current:\r\n",
      "total 8.0K\r\n",
      "4.0K drwxr-xr-x 3 root root 4.0K Aug 10 05:28 eval_model_dir\r\n",
      "4.0K drwxr-xr-x 4 root root 4.0K Aug 10 05:28 serving_model_dir\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/eval_model_dir:\r\n",
      "total 4.0K\r\n",
      "4.0K drwxr-xr-x 4 root root 4.0K Aug 10 05:28 1565414889\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889:\r\n",
      "total 864K\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:28 assets\r\n",
      "856K -rw-r--r-- 1 root root 854K Aug 10 05:28 saved_model.pb\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:28 variables\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889/assets:\r\n",
      "total 8.0K\r\n",
      "4.0K -rw-r--r-- 1 root root 1.3K Aug 10 05:28 vocab_compute_and_apply_vocabulary_1_vocabulary\r\n",
      "4.0K -rw-r--r-- 1 root root   56 Aug 10 05:28 vocab_compute_and_apply_vocabulary_vocabulary\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/eval_model_dir/1565414889/variables:\r\n",
      "total 68K\r\n",
      "4.0K -rw-r--r-- 1 root root   8 Aug 10 05:28 variables.data-00000-of-00002\r\n",
      " 60K -rw-r--r-- 1 root root 58K Aug 10 05:28 variables.data-00001-of-00002\r\n",
      "4.0K -rw-r--r-- 1 root root 995 Aug 10 05:28 variables.index\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/serving_model_dir:\r\n",
      "total 6.1M\r\n",
      "4.0K -rw-r--r-- 1 root root   89 Aug 10 05:27 checkpoint\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:27 eval_chicago-taxi-eval\r\n",
      "3.6M -rw-r--r-- 1 root root 3.6M Aug 10 05:28 events.out.tfevents.1565414831.5abb5d762fe2\r\n",
      "4.0K drwxr-xr-x 3 root root 4.0K Aug 10 05:28 export\r\n",
      "1.6M -rw-r--r-- 1 root root 1.6M Aug 10 05:27 graph.pbtxt\r\n",
      "4.0K -rw-r--r-- 1 root root    8 Aug 10 05:27 model.ckpt-10000.data-00000-of-00002\r\n",
      "124K -rw-r--r-- 1 root root 124K Aug 10 05:27 model.ckpt-10000.data-00001-of-00002\r\n",
      "4.0K -rw-r--r-- 1 root root 2.1K Aug 10 05:27 model.ckpt-10000.index\r\n",
      "828K -rw-r--r-- 1 root root 828K Aug 10 05:27 model.ckpt-10000.meta\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/serving_model_dir/eval_chicago-taxi-eval:\r\n",
      "total 1.3M\r\n",
      "1.3M -rw-r--r-- 1 root root 1.3M Aug 10 05:28 events.out.tfevents.1565414849.5abb5d762fe2\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/serving_model_dir/export:\r\n",
      "total 4.0K\r\n",
      "4.0K drwxr-xr-x 3 root root 4.0K Aug 10 05:28 chicago-taxi\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/serving_model_dir/export/chicago-taxi:\r\n",
      "total 4.0K\r\n",
      "4.0K drwxr-xr-x 4 root root 4.0K Aug 10 05:28 1565414887\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/serving_model_dir/export/chicago-taxi/1565414887:\r\n",
      "total 564K\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:28 assets\r\n",
      "556K -rw-r--r-- 1 root root 554K Aug 10 05:28 saved_model.pb\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:28 variables\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/serving_model_dir/export/chicago-taxi/1565414887/assets:\r\n",
      "total 8.0K\r\n",
      "4.0K -rw-r--r-- 1 root root 1.3K Aug 10 05:28 vocab_compute_and_apply_vocabulary_1_vocabulary\r\n",
      "4.0K -rw-r--r-- 1 root root   56 Aug 10 05:28 vocab_compute_and_apply_vocabulary_vocabulary\r\n",
      "\r\n",
      "/root/taxi/data/simple/trainer/current/serving_model_dir/export/chicago-taxi/1565414887/variables:\r\n",
      "total 68K\r\n",
      "4.0K -rw-r--r-- 1 root root   8 Aug 10 05:28 variables.data-00000-of-00002\r\n",
      " 60K -rw-r--r-- 1 root root 58K Aug 10 05:28 variables.data-00001-of-00002\r\n",
      "4.0K -rw-r--r-- 1 root root 995 Aug 10 05:28 variables.index\r\n",
      "\r\n",
      "/root/taxi/data/simple/transform:\r\n",
      "total 8.0K\r\n",
      "4.0K drwxr-xr-x 5 root root 4.0K Aug 10 05:27 transform_output\r\n",
      "4.0K drwxr-xr-x 4 root root 4.0K Aug 10 05:27 transformed_examples\r\n",
      "\r\n",
      "/root/taxi/data/simple/transform/transform_output:\r\n",
      "total 12K\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:27 metadata\r\n",
      "4.0K drwxr-xr-x 4 root root 4.0K Aug 10 05:27 transform_fn\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:27 transformed_metadata\r\n",
      "\r\n",
      "/root/taxi/data/simple/transform/transform_output/metadata:\r\n",
      "total 4.0K\r\n",
      "4.0K -rw-r--r-- 1 root root 916 Aug 10 05:27 schema.pbtxt\r\n",
      "\r\n",
      "/root/taxi/data/simple/transform/transform_output/transform_fn:\r\n",
      "total 84K\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:27 assets\r\n",
      " 76K -rw-r--r-- 1 root root  76K Aug 10 05:27 saved_model.pb\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:27 variables\r\n",
      "\r\n",
      "/root/taxi/data/simple/transform/transform_output/transform_fn/assets:\r\n",
      "total 8.0K\r\n",
      "4.0K -rw-r--r-- 1 root root 1.3K Aug 10 05:27 vocab_compute_and_apply_vocabulary_1_vocabulary\r\n",
      "4.0K -rw-r--r-- 1 root root   56 Aug 10 05:27 vocab_compute_and_apply_vocabulary_vocabulary\r\n",
      "\r\n",
      "/root/taxi/data/simple/transform/transform_output/transform_fn/variables:\r\n",
      "total 0\r\n",
      "\r\n",
      "/root/taxi/data/simple/transform/transform_output/transformed_metadata:\r\n",
      "total 4.0K\r\n",
      "4.0K -rw-r--r-- 1 root root 2.2K Aug 10 05:27 schema.pbtxt\r\n",
      "\r\n",
      "/root/taxi/data/simple/transform/transformed_examples:\r\n",
      "total 8.0K\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:27 eval\r\n",
      "4.0K drwxr-xr-x 2 root root 4.0K Aug 10 05:27 train\r\n",
      "\r\n",
      "/root/taxi/data/simple/transform/transformed_examples/eval:\r\n",
      "total 176K\r\n",
      "176K -rw-r--r-- 1 root root 173K Aug 10 05:27 transformed_examples-00000-of-00001.gz\r\n",
      "\r\n",
      "/root/taxi/data/simple/transform/transformed_examples/train:\r\n",
      "total 352K\r\n",
      "352K -rw-r--r-- 1 root root 349K Aug 10 05:27 transformed_examples-00000-of-00001.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -Rlhs /root/taxi/data/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_dir(model_analyzer):\n",
    "    artifact = model_analyzer.outputs.output.get()\n",
    "    return types.get_single_uri(artifact)\n",
    "    \n",
    "eval_dir = get_eval_dir(model_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "result = tfma.load_eval_result(eval_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f91addc2bcc470895c9ff51503864e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SlicingMetricsViewer(config={'weightedExamplesColumn': 'post_export_metrics/example_count'}, data=[{'slice': '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfma.view.render_slicing_metrics(result, slicing_column='trip_start_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b35dcf6a2c4fbf87bab595c7261e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PlotViewer(config={'sliceName': 'trip_start_hour:10', 'metricKeys': {'aucPlot': {'metricName': 'confusionMatri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "tfma.view.render_plot(result, tfma.slicer.SingleSliceSpec(features=[('trip_start_hour', 10)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
